{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cECQfwPeTC_S"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0n0NLsXcK_Y",
        "outputId": "365edaec-46c1-4ce6-a1ab-7b04aea173aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n",
            "  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-snhqth6_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-snhqth6_\n",
            "  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit 10d2f8a026d73eada861c7d51064f7e24d8f482c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer-lens==0.0.0)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens==0.0.0)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer-lens==0.0.0)\n",
            "  Downloading jaxtyping-0.2.20-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.5.2)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.66.1)\n",
            "Collecting transformers>=4.25.1 (from transformer-lens==0.0.0)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb>=0.13.5 (from transformer-lens==0.0.0)\n",
            "  Downloading wandb-0.15.8-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n",
            "Collecting xxhash (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (6.0.1)\n",
            "Collecting typeguard>=2.13.3 (from jaxtyping>=0.2.11->transformer-lens==0.0.0)\n",
            "  Downloading typeguard-4.1.1-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (4.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.6)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading sentry_sdk-1.29.2-py2.py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.6/215.6 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: transformer-lens, pathtools\n",
            "  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=105856 sha256=8b8569bc6ad00f3b4d7748e92dcaec0688a67652fe6b37f8bea495ca076ad502\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9bqlaz7g/wheels/8a/1e/37/ffb9c15454a1725b13a9d9f5e74fb91725048884ad734b8c1f\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=0d7c2a17c9fa2eb8b34127dff62de29bc8f73cfce9267cd6d606e6a859423b2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built transformer-lens pathtools\n",
            "Installing collected packages: tokenizers, safetensors, pathtools, xxhash, typeguard, smmap, setproctitle, sentry-sdk, fancy-einsum, einops, docker-pycreds, dill, beartype, multiprocess, jaxtyping, huggingface-hub, gitdb, transformers, GitPython, wandb, datasets, transformer-lens\n",
            "Successfully installed GitPython-3.1.32 beartype-0.14.1 datasets-2.14.4 dill-0.3.7 docker-pycreds-0.4.0 einops-0.6.1 fancy-einsum-0.0.3 gitdb-4.0.10 huggingface-hub-0.16.4 jaxtyping-0.2.20 multiprocess-0.70.15 pathtools-0.1.2 safetensors-0.3.2 sentry-sdk-1.29.2 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.13.3 transformer-lens-0.0.0 transformers-4.31.0 typeguard-4.1.1 wandb-0.15.8 xxhash-3.3.0\n",
            "Collecting git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
            "  Cloning https://github.com/callummcdougall/CircuitsVis.git to /tmp/pip-req-build-o3ckp9j5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/callummcdougall/CircuitsVis.git /tmp/pip-req-build-o3ckp9j5\n",
            "  Resolved https://github.com/callummcdougall/CircuitsVis.git to commit e73cbe5c8f84ad27a6069e525e208b6d11d049b6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting importlib-metadata<6.0.0,>=5.1.0 (from circuitsvis==0.0.0)\n",
            "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from circuitsvis==0.0.0) (1.23.5)\n",
            "Requirement already satisfied: torch<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis==0.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis==0.0.0) (3.16.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<3.0,>=2.0->circuitsvis==0.0.0) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<3.0,>=2.0->circuitsvis==0.0.0) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0,>=2.0->circuitsvis==0.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0,>=2.0->circuitsvis==0.0.0) (1.3.0)\n",
            "Building wheels for collected packages: circuitsvis\n",
            "  Building wheel for circuitsvis (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for circuitsvis: filename=circuitsvis-0.0.0-py3-none-any.whl size=6170536 sha256=b5218932ec5b1e88f894649afdae89848e95800f221493a398a1b86bccad8f53\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ligfikwc/wheels/86/be/ad/78078aba9344d200aad61b63d35cdaecdec160212f039eed74\n",
            "Successfully built circuitsvis\n",
            "Installing collected packages: importlib-metadata, circuitsvis\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.8.0\n",
            "    Uninstalling importlib-metadata-6.8.0:\n",
            "      Successfully uninstalled importlib-metadata-6.8.0\n",
            "Successfully installed circuitsvis-0.0.0 importlib-metadata-5.2.0\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "%pip install git+https://github.com/neelnanda-io/TransformerLens.git\n",
        "%pip install git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn_t6ggySXUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2831df-b192-4717-c0ef-d9c359e3237a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (23.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install plotly\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch import Tensor\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import tqdm.auto as tqdm\n",
        "import random\n",
        "from pathlib import Path\n",
        "# import plotly.express as px\n",
        "from torch.utils.data import DataLoader\n",
        "from typing import Union, List, Optional, Callable, Tuple, Dict, Literal, Set\n",
        "from jaxtyping import Float, Int\n",
        "from functools import partial\n",
        "import copy\n",
        "\n",
        "import itertools\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import dataclasses\n",
        "import datasets\n",
        "from IPython.display import HTML\n",
        "\n",
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.utils import to_numpy\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache, patching\n",
        "\n",
        "import plotly.express as px\n",
        "import circuitsvis as cv\n",
        "import os, sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q_GOKh0e0jr",
        "outputId": "df6a8500-9348-43bb-82a4-dec33a905e1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-EbXu2Wr7k8",
        "outputId": "f56a274d-605b-4bd4-e362-34c12ea90a54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-16 03:44:13--  https://github.com/callummcdougall/path_patching/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/callummcdougall/path_patching/zip/refs/heads/main [following]\n",
            "--2023-08-16 03:44:14--  https://codeload.github.com/callummcdougall/path_patching/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.255.121\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.255.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [ <=>                ]  18.40K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2023-08-16 03:44:14 (2.12 MB/s) - ‘main.zip’ saved [18839]\n",
            "\n",
            "Archive:  main.zip\n",
            "7d48069215eb3959940eb4c459d6e49a94d53aa2\n",
            "  inflating: path_patching-main/ioi_dataset.py  \n",
            "Archive:  main.zip\n",
            "7d48069215eb3959940eb4c459d6e49a94d53aa2\n",
            "  inflating: path_patching-main/path_patching.py  \n"
          ]
        }
      ],
      "source": [
        "#!sudo apt install unzip\n",
        "if not os.path.exists(\"path_patching.py\"):\n",
        "        !wget https://github.com/callummcdougall/path_patching/archive/refs/heads/main.zip\n",
        "        !unzip main.zip 'path_patching-main/ioi_dataset.py'\n",
        "        !unzip main.zip 'path_patching-main/path_patching.py'\n",
        "        sys.path.append(\"path_patching-main\")\n",
        "        os.remove(\"main.zip\")\n",
        "        os.rename(\"path_patching-main/ioi_dataset.py\", \"ioi_dataset.py\")\n",
        "        os.rename(\"path_patching-main/path_patching.py\", \"path_patching.py\")\n",
        "        os.rmdir(\"path_patching-main\")\n",
        "\n",
        "from path_patching import Node, IterNode, path_patch, act_patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUkXJ1EiS5kx",
        "outputId": "8c42b9b6-ec6a-42eb-8627-34eec1543772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/neelnanda-io/neel-plotly.git\n",
            "  Cloning https://github.com/neelnanda-io/neel-plotly.git to /tmp/pip-req-build-cmu188cc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/neel-plotly.git /tmp/pip-req-build-cmu188cc\n",
            "  Resolved https://github.com/neelnanda-io/neel-plotly.git to commit 6dc24b26f8dec991908479d7445dae496b3430b7\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from neel-plotly==0.0.0) (0.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from neel-plotly==0.0.0) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from neel-plotly==0.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from neel-plotly==0.0.0) (5.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from neel-plotly==0.0.0) (4.66.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from neel-plotly==0.0.0) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->neel-plotly==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->neel-plotly==0.0.0) (2023.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->neel-plotly==0.0.0) (8.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly->neel-plotly==0.0.0) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->neel-plotly==0.0.0) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->neel-plotly==0.0.0) (16.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->neel-plotly==0.0.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->neel-plotly==0.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->neel-plotly==0.0.0) (1.3.0)\n",
            "Building wheels for collected packages: neel-plotly\n",
            "  Building wheel for neel-plotly (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neel-plotly: filename=neel_plotly-0.0.0-py3-none-any.whl size=10186 sha256=486850bb8f0f09c3da1fc4d9aaa2eac797b20836ac32e213898c500089326933\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-14q7egc3/wheels/32/cf/25/0103b4be02266c40faf008ffa9565a2ba07d1c63118fccc390\n",
            "Successfully built neel-plotly\n",
            "Installing collected packages: neel-plotly\n",
            "Successfully installed neel-plotly-0.0.0\n"
          ]
        }
      ],
      "source": [
        "%pip install git+https://github.com/neelnanda-io/neel-plotly.git\n",
        "from neel_plotly import imshow, line, scatter, histogram\n",
        "import tqdm\n",
        "torch.set_grad_enabled(False)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U kaleido"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q80S5LpCjg3p",
        "outputId": "06cd119f-c3cd-496b-f19f-bd660203cfe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kaleido\n",
            "Successfully installed kaleido-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8q6OIui0b6R0",
        "outputId": "77ddad52-1caa-4044-ebc2-685934e4da0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vlEXgxRWrZw"
      },
      "outputs": [],
      "source": [
        "update_layout_set = {\n",
        "    \"xaxis_range\", \"yaxis_range\", \"hovermode\", \"xaxis_title\", \"yaxis_title\", \"colorbar\", \"colorscale\", \"coloraxis\", \"title_x\", \"bargap\", \"bargroupgap\", \"xaxis_tickformat\",\n",
        "    \"yaxis_tickformat\", \"title_y\", \"legend_title_text\", \"xaxis_showgrid\", \"xaxis_gridwidth\", \"xaxis_gridcolor\", \"yaxis_showgrid\", \"yaxis_gridwidth\", \"yaxis_gridcolor\",\n",
        "    \"showlegend\", \"xaxis_tickmode\", \"yaxis_tickmode\", \"xaxis_tickangle\", \"yaxis_tickangle\", \"margin\", \"xaxis_visible\", \"yaxis_visible\", \"bargap\", \"bargroupgap\"\n",
        "}\n",
        "\n",
        "def imshow(tensor, return_fig = False, renderer=None, **kwargs):\n",
        "    kwargs_post = {k: v for k, v in kwargs.items() if k in update_layout_set}\n",
        "    kwargs_pre = {k: v for k, v in kwargs.items() if k not in update_layout_set}\n",
        "    facet_labels = kwargs_pre.pop(\"facet_labels\", None)\n",
        "    border = kwargs_pre.pop(\"border\", False)\n",
        "    if \"color_continuous_scale\" not in kwargs_pre:\n",
        "        kwargs_pre[\"color_continuous_scale\"] = \"RdBu\"\n",
        "    if \"margin\" in kwargs_post and isinstance(kwargs_post[\"margin\"], int):\n",
        "        kwargs_post[\"margin\"] = dict.fromkeys(list(\"tblr\"), kwargs_post[\"margin\"])\n",
        "    if \"color_continuous_midpoint\" not in kwargs_pre:\n",
        "        fig = px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, **kwargs_pre)\n",
        "    else:\n",
        "        fig = px.imshow(utils.to_numpy(tensor), **kwargs_pre)\n",
        "    if facet_labels:\n",
        "        for i, label in enumerate(facet_labels):\n",
        "            fig.layout.annotations[i]['text'] = label\n",
        "    if border:\n",
        "        fig.update_xaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        "        fig.update_yaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        "    # things like `xaxis_tickmode` should be applied to all subplots. This is super janky lol but I'm under time pressure\n",
        "    for setting in [\"tickangle\"]:\n",
        "      if f\"xaxis_{setting}\" in kwargs_post:\n",
        "          i = 2\n",
        "          while f\"xaxis{i}\" in fig[\"layout\"]:\n",
        "            kwargs_post[f\"xaxis{i}_{setting}\"] = kwargs_post[f\"xaxis_{setting}\"]\n",
        "            i += 1\n",
        "    fig.update_layout(**kwargs_post)\n",
        "    if return_fig:\n",
        "      return fig\n",
        "    else:\n",
        "        fig.show(renderer=renderer)\n",
        "\n",
        "\n",
        "def hist(tensor, renderer=None, **kwargs):\n",
        "    kwargs_post = {k: v for k, v in kwargs.items() if k in update_layout_set}\n",
        "    kwargs_pre = {k: v for k, v in kwargs.items() if k not in update_layout_set}\n",
        "    names = kwargs_pre.pop(\"names\", None)\n",
        "    if \"barmode\" not in kwargs_post:\n",
        "        kwargs_post[\"barmode\"] = \"overlay\"\n",
        "    if \"bargap\" not in kwargs_post:\n",
        "        kwargs_post[\"bargap\"] = 0.0\n",
        "    if \"margin\" in kwargs_post and isinstance(kwargs_post[\"margin\"], int):\n",
        "        kwargs_post[\"margin\"] = dict.fromkeys(list(\"tblr\"), kwargs_post[\"margin\"])\n",
        "    fig = px.histogram(x=tensor, **kwargs_pre).update_layout(**kwargs_post)\n",
        "    if names is not None:\n",
        "        for i in range(len(fig.data)):\n",
        "            fig.data[i][\"name\"] = names[i // 2]\n",
        "    fig.show(renderer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dv-vp7D36Wbp"
      },
      "outputs": [],
      "source": [
        "from plotly import graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "506a46f8c2804e4e80c097f121ebf770",
            "9ce8558086424ca1b71642ca51c8a3ef",
            "4228c933053149ff8de0b2280e567159",
            "7bafeb6aebb043718a3e25fc3e915684",
            "b06ce165db014a8d85899d711a36aa28",
            "063b8e295a5945b1aa61fa81212b81ec",
            "e51c208c8345426c9af3677382636cdd",
            "5a720266ceee413cb671125c84794a6b",
            "7d4ef212d224461e8209ce14d126cff2",
            "8bcea851e4ac47759ad3a97406854889",
            "3f8abd16404341ca83b21b717d4256ec",
            "845c2cba2e28456d94d54c8d1703f820",
            "1b6e1eb73bc84d72ac2378ab67b6a532",
            "e042b258db54416a905a08ea483e56a2",
            "dedd17db78874e4b979d9df1e18880a2",
            "2d6307aed0594520b6365eb7423df1a5",
            "b444a45124ea4b0c9dbae93cf3f81d87",
            "a77346a2c7004d828323b46a51d6cace",
            "2dbece5ace5a4c199c010c56aee6f0f5",
            "80e70f18076846a2bc578e418d3652eb",
            "d80df97eb85645ec984fe0de19b18cd0",
            "fb4d2408dd994e6da952bd9d2323af71",
            "fc05fdfa1bfd471e860b4551ae348d70",
            "1df76e67d6fb4036bda6f09fa21ccb01",
            "78ccd3abd5574ce8b8597ad735fc4863",
            "f58b4a27a9e442bf98e19acd0e770c41",
            "3d0b7ffa77794423a3a99cc8f786818c",
            "2a3eeb97fec24b9b8b5c2c4f71a7edbd",
            "3c56ef4d7a6540e39608e00bbda8d7a7",
            "1b9d055deab9428fb307d32d80182e55",
            "0295381282764dadbb4b2475467128fb",
            "f6734728627b42ca9a1c51d7dca372d0",
            "f7a945af172043e9b492f3b4b5430f89",
            "2dc7dc7fb3094b8f9d840d6a0c5e9669",
            "f3642d670de84023937132a0f5712c89",
            "dd5ff3730d554ea4b3af65caadd70901",
            "9fea82acd513401a8b2c8db5d4ec694e",
            "1d0d42f173aa490dbd3a5bab5f257dff",
            "91865eee9ccf4f71b6129d6adbee35c0",
            "923fa28cefb649a8be7fff1fd50085af",
            "ef1c463526414441924170e5d7306e5e",
            "d06d580f717a432a9b9053a05e511907",
            "da32c362df834daeb890b777495e726d",
            "acf4c0bcb2b544edb6344e4bc6bfc20a",
            "ae5cb0516ef24f0aa8cc786c7a662598",
            "49752dd8f2ad4256b591a5cf29279110",
            "c0cc4ae6886a4d0794b5c183ab82660a",
            "ca71a2483c5444de9c8d32ba48e5b3a5",
            "e522567d78414e62a7b62cd7701ea6d4",
            "cfbc70025a6c4711aca9080fa180fcbf",
            "cadff10383da46e4b969ed1f49a572f3",
            "a20d17ca63d14366a3fa785c4ad51940",
            "af7965edc273417e86b31146ca62fe0a",
            "eb9099c296454d21b1dfac86fcd180c2",
            "091a47613ccf4cc7bef0ac82a83a10da",
            "d982787f18924734b1b7c131bce69ee5",
            "e64d51689e8a4d12be5f066288cf4ae3",
            "5752a7b4a93a430da6b1fd5e9181cbb2",
            "42c8c84bb766401aa2e3559173ac87e7",
            "20203de075f149eb958dc37d2518b26c",
            "5b13ce7ecd684470a650cbf6b1c73180",
            "b9a95c0aa7294f15879b14b17170fb9f",
            "1b8ad636023744c3b2fd74e31c10815c",
            "a624540f260d400f9a969044449e6e4c",
            "e858548fc39c49e19e15fded80ba0368",
            "a2e12d17d617402a87a6fa26db3e3e6d"
          ]
        },
        "id": "o8KgURIVz1gf",
        "outputId": "8087589c-ae79-41d2-fd45-50c2e40f5006"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "506a46f8c2804e4e80c097f121ebf770"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "845c2cba2e28456d94d54c8d1703f820"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc05fdfa1bfd471e860b4551ae348d70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2dc7dc7fb3094b8f9d840d6a0c5e9669"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae5cb0516ef24f0aa8cc786c7a662598"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d982787f18924734b1b7c131bce69ee5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using pad_token, but it is not set yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "model = HookedTransformer.from_pretrained(\n",
        "    \"gpt2-small\",\n",
        "    center_unembed=True,\n",
        "    center_writing_weights=True,\n",
        "    fold_ln=True,\n",
        "    refactor_factored_attn_matrices=True,\n",
        "\n",
        "    device = device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Daje7Fw1m2W1"
      },
      "source": [
        "# Model + Dataset Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv5obrKX0dZD"
      },
      "source": [
        "## lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxP_Xvfc0fb-"
      },
      "outputs": [],
      "source": [
        "objects = [\n",
        "  \"perfume\",\n",
        "  \"scissors\",\n",
        "  \"drum\",\n",
        "  \"trumpet\",\n",
        "  \"phone\",\n",
        "  \"football\",\n",
        "  \"token\",\n",
        "  \"bracelet\",\n",
        "  \"badge\",\n",
        "  \"novel\",\n",
        "  \"pillow\",\n",
        "  \"coffee\",\n",
        "  \"skirt\",\n",
        "  \"balloon\",\n",
        "  \"photo\",\n",
        "  \"plate\",\n",
        "  \"headphones\",\n",
        "  \"flask\",\n",
        "  \"menu\",\n",
        "  \"compass\",\n",
        "  \"belt\",\n",
        "  \"wallet\",\n",
        "  \"pen\",\n",
        "  \"mask\",\n",
        "  \"ticket\",\n",
        "  \"suitcase\",\n",
        "  \"sunscreen\",\n",
        "  \"letter\",\n",
        "  \"torch\",\n",
        "  \"cocktail\",\n",
        "  \"spoon\",\n",
        "  \"comb\",\n",
        "  \"shirt\",\n",
        "  \"coin\",\n",
        "  \"cable\",\n",
        "  \"button\",\n",
        "  \"recorder\",\n",
        "  \"frame\",\n",
        "  \"key\",\n",
        "  \"card\",\n",
        "  \"canvas\",\n",
        "  \"packet\",\n",
        "  \"bowl\",\n",
        "  \"receipt\",\n",
        "  \"pan\",\n",
        "  \"report\",\n",
        "  \"book\",\n",
        "  \"cap\",\n",
        "  \"charger\",\n",
        "  \"rake\",\n",
        "  \"fork\",\n",
        "  \"map\",\n",
        "  \"soap\",\n",
        "  \"cash\",\n",
        "  \"whistle\",\n",
        "  \"rope\",\n",
        "  \"violin\",\n",
        "  \"scale\",\n",
        "  \"diary\",\n",
        "  \"ruler\",\n",
        "  \"mouse\",\n",
        "  \"toy\",\n",
        "  \"cd\",\n",
        "  \"dress\",\n",
        "  \"shampoo\",\n",
        "  \"flashlight\",\n",
        "  \"newspaper\",\n",
        "  \"puzzle\",\n",
        "  \"tripod\",\n",
        "  \"brush\",\n",
        "  \"cane\",\n",
        "  \"whisk\",\n",
        "  \"tablet\",\n",
        "  \"purse\",\n",
        "  \"paper\",\n",
        "  \"vinyl\",\n",
        "  \"camera\",\n",
        "  \"guitar\",\n",
        "  \"necklace\",\n",
        "  \"mirror\",\n",
        "  \"cup\",\n",
        "  \"cloth\",\n",
        "  \"flag\",\n",
        "  \"socks\",\n",
        "  \"shovel\",\n",
        "  \"cooler\",\n",
        "  \"hammer\",\n",
        "  \"shoes\",\n",
        "  \"chalk\",\n",
        "  \"wrench\",\n",
        "  \"towel\",\n",
        "  \"glove\",\n",
        "  \"speaker\",\n",
        "  \"remote\",\n",
        "  \"leash\",\n",
        "  \"magazine\",\n",
        "  \"notebook\",\n",
        "  \"candle\",\n",
        "  \"feather\",\n",
        "  \"gloves\",\n",
        "  \"mascara\",\n",
        "  \"charcoal\",\n",
        "  \"pills\",\n",
        "  \"laptop\",\n",
        "  \"pamphlet\",\n",
        "  \"knife\",\n",
        "  \"kettle\",\n",
        "  \"scarf\",\n",
        "  \"tie\",\n",
        "  \"goggles\",\n",
        "  \"fins\",\n",
        "  \"lipstick\",\n",
        "  \"shorts\",\n",
        "  \"joystick\",\n",
        "  \"bookmark\",\n",
        "  \"microphone\",\n",
        "  \"hat\",\n",
        "  \"pants\",\n",
        "  \"umbrella\",\n",
        "  \"harness\",\n",
        "  \"roller\",\n",
        "  \"blanket\",\n",
        "  \"folder\",\n",
        "  \"bag\",\n",
        "  \"crate\",\n",
        "  \"pot\",\n",
        "  \"watch\",\n",
        "  \"mug\",\n",
        "  \"sandwich\",\n",
        "  \"yarn\",\n",
        "  \"ring\",\n",
        "  \"backpack\",\n",
        "  \"glasses\",\n",
        "  \"pencil\",\n",
        "  \"broom\",\n",
        "  \"baseball\",\n",
        "  \"basket\",\n",
        "  \"loaf\",\n",
        "  \"coins\",\n",
        "  \"bakery\",\n",
        "  \"tape\",\n",
        "  \"helmet\",\n",
        "  \"bible\",\n",
        "  \"jacket\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkNghQGv640F"
      },
      "outputs": [],
      "source": [
        "names = [\n",
        "  \" Sebastian\",\n",
        "  \" Jack\",\n",
        "  \" Jeremiah\",\n",
        "  \" Ellie\",\n",
        "  \" Sean\",\n",
        "  \" William\",\n",
        "  \" Caroline\",\n",
        "  \" Cooper\",\n",
        "  \" Xavier\",\n",
        "  \" Ian\",\n",
        "  \" Mark\",\n",
        "  \" Brian\",\n",
        "  \" Carter\",\n",
        "  \" Nicholas\",\n",
        "  \" Peyton\",\n",
        "  \" Luke\",\n",
        "  \" Alexis\",\n",
        "  \" Ted\",\n",
        "  \" Jan\",\n",
        "  \" Ty\",\n",
        "  \" Jen\",\n",
        "  \" Sophie\",\n",
        "  \" Kelly\",\n",
        "  \" Claire\",\n",
        "  \" Leo\",\n",
        "  \" Nolan\",\n",
        "  \" Kyle\",\n",
        "  \" Ashley\",\n",
        "  \" Samantha\",\n",
        "  \" Avery\",\n",
        "  \" Jackson\",\n",
        "  \" Hudson\",\n",
        "  \" Rebecca\",\n",
        "  \" Robert\",\n",
        "  \" Joshua\",\n",
        "  \" Olivia\",\n",
        "  \" Reagan\",\n",
        "  \" Lauren\",\n",
        "  \" Chris\",\n",
        "  \" Chelsea\",\n",
        "  \" Deb\",\n",
        "  \" Chloe\",\n",
        "  \" Madison\",\n",
        "  \" Kent\",\n",
        "  \" Thomas\",\n",
        "  \" Oliver\",\n",
        "  \" Dylan\",\n",
        "  \" Ann\",\n",
        "  \" Audrey\",\n",
        "  \" Greg\",\n",
        "  \" Henry\",\n",
        "  \" Emma\",\n",
        "  \" Josh\",\n",
        "  \" Mary\",\n",
        "  \" Daniel\",\n",
        "  \" Carl\",\n",
        "  \" Scarlett\",\n",
        "  \" Ethan\",\n",
        "  \" Levi\",\n",
        "  \" Eli\",\n",
        "  \" James\",\n",
        "  \" Patrick\",\n",
        "  \" Isaac\",\n",
        "  \" Brooke\",\n",
        "  \" Alexa\",\n",
        "  \" Eleanor\",\n",
        "  \" Anthony\",\n",
        "  \" Logan\",\n",
        "  \" Damian\",\n",
        "  \" Jordan\",\n",
        "  \" Tyler\",\n",
        "  \" Haley\",\n",
        "  \" Isabel\",\n",
        "  \" Alan\",\n",
        "  \" Lucas\",\n",
        "  \" Dave\",\n",
        "  \" Susan\",\n",
        "  \" Joseph\",\n",
        "  \" Brad\",\n",
        "  \" Joe\",\n",
        "  \" Vincent\",\n",
        "  \" Maya\",\n",
        "  \" Will\",\n",
        "  \" Jessica\",\n",
        "  \" Sophia\",\n",
        "  \" Angel\",\n",
        "  \" Steve\",\n",
        "  \" Benjamin\",\n",
        "  \" Eric\",\n",
        "  \" Cole\",\n",
        "  \" Justin\",\n",
        "  \" Amy\",\n",
        "  \" Nora\",\n",
        "  \" Seth\",\n",
        "  \" Anna\",\n",
        "  \" Stella\",\n",
        "  \" Frank\",\n",
        "  \" Larry\",\n",
        "  \" Alexandra\",\n",
        "  \" Ken\",\n",
        "  \" Lucy\",\n",
        "  \" Katherine\",\n",
        "  \" Leah\",\n",
        "  \" Adrian\",\n",
        "  \" David\",\n",
        "  \" Liam\",\n",
        "  \" Christian\",\n",
        "  \" John\",\n",
        "  \" Nathaniel\",\n",
        "  \" Andrea\",\n",
        "  \" Laura\",\n",
        "  \" Kim\",\n",
        "  \" Kevin\",\n",
        "  \" Colin\",\n",
        "  \" Marcus\",\n",
        "  \" Emily\",\n",
        "  \" Sarah\",\n",
        "  \" Steven\",\n",
        "  \" Eva\",\n",
        "  \" Richard\",\n",
        "  \" Faith\",\n",
        "  \" Amelia\",\n",
        "  \" Harper\",\n",
        "  \" Keith\",\n",
        "  \" Ross\",\n",
        "  \" Megan\",\n",
        "  \" Brooklyn\",\n",
        "  \" Tom\",\n",
        "  \" Grant\",\n",
        "  \" Savannah\",\n",
        "  \" Riley\",\n",
        "  \" Julia\",\n",
        "  \" Piper\",\n",
        "  \" Wyatt\",\n",
        "  \" Jake\",\n",
        "  \" Nathan\",\n",
        "  \" Nick\",\n",
        "  \" Blake\",\n",
        "  \" Ryan\",\n",
        "  \" Jason\",\n",
        "  \" Chase\",]\n",
        "saved_names = names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WF0NiXJB0knJ"
      },
      "outputs": [],
      "source": [
        "# names = [\n",
        "\n",
        "#     \" Mary\", \" John\",\n",
        "#     \" Tom\", \" James\",\n",
        "#     \" Dan\", \" Sid\"  ,\n",
        "#     \" Martin\", \" Amy\",\n",
        "#     \" Cody\", \" Jay\",\n",
        "#     \" Jack\", \" Jill\",\n",
        "#     \" Mark\", \" Martin\",\n",
        "#     \" Sarah\", \" Emily\",\n",
        "#     \" Cole\", \" George\",\n",
        "#     \" Kai\", \" Bryce\",\n",
        "# ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eU8W9sF0sJj"
      },
      "outputs": [],
      "source": [
        "places = [\n",
        "  \"swamp\",\n",
        "  \"school\",\n",
        "  \"volcano\",\n",
        "  \"hotel\",\n",
        "  \"subway\",\n",
        "  \"arcade\",\n",
        "  \"library\",\n",
        "  \"island\",\n",
        "  \"convent\",\n",
        "  \"pool\",\n",
        "  \"mall\",\n",
        "  \"prison\",\n",
        "  \"quarry\",\n",
        "  \"temple\",\n",
        "  \"ruins\",\n",
        "  \"factory\",\n",
        "  \"zoo\",\n",
        "  \"mansion\",\n",
        "  \"tavern\",\n",
        "  \"planet\",\n",
        "  \"forest\",\n",
        "  \"airport\",\n",
        "  \"pharmacy\",\n",
        "  \"church\",\n",
        "  \"park\",\n",
        "  \"delta\",\n",
        "  \"mosque\",\n",
        "  \"valley\",\n",
        "  \"casino\",\n",
        "  \"pyramid\",\n",
        "  \"aquarium\",\n",
        "  \"castle\",\n",
        "  \"ranch\",\n",
        "  \"clinic\",\n",
        "  \"theater\",\n",
        "  \"gym\",\n",
        "  \"studio\",\n",
        "  \"station\",\n",
        "  \"palace\",\n",
        "  \"stadium\",\n",
        "  \"museum\",\n",
        "  \"plateau\",\n",
        "  \"home\",\n",
        "  \"resort\",\n",
        "  \"garage\",\n",
        "  \"reef\",\n",
        "  \"lounge\",\n",
        "  \"chapel\",\n",
        "  \"canyon\",\n",
        "  \"brewery\",\n",
        "  \"market\",\n",
        "  \"jungle\",\n",
        "  \"office\",\n",
        "  \"cottage\",\n",
        "  \"street\",\n",
        "  \"gallery\",\n",
        "  \"landfill\",\n",
        "  \"glacier\",\n",
        "  \"barracks\",\n",
        "  \"bakery\",\n",
        "  \"synagogue\",\n",
        "  \"jersey\",\n",
        "  \"plaza\",\n",
        "  \"garden\",\n",
        "  \"cafe\",\n",
        "  \"cinema\",\n",
        "  \"beach\",\n",
        "  \"harbor\",\n",
        "  \"circus\",\n",
        "  \"bridge\",\n",
        "  \"monastery\",\n",
        "  \"desert\",\n",
        "  \"tunnel\",\n",
        "  \"motel\",\n",
        "  \"fortress\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjz17uXf0eje"
      },
      "source": [
        "## code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNUmu0W2z4xZ"
      },
      "outputs": [],
      "source": [
        "template = \"When{name_A} and{name_B} went to the {place},{name_C} gave the {object} to\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkXEo_ew0yIl"
      },
      "outputs": [],
      "source": [
        "# prompt: generate a list of prompts using the template. ensure that no prompt uses the same two names\n",
        "\n",
        "import random\n",
        "\n",
        "# Create a list of all possible pairs of names\n",
        "names_list = list(itertools.combinations(names, 2))\n",
        "\n",
        "# Create a list of prompts\n",
        "prompts = []\n",
        "counter_prompts = []\n",
        "\n",
        "\n",
        "name_pairs = []\n",
        "#counter_name_pairs = []\n",
        "\n",
        "for name_pair in names_list:\n",
        "    name_A, name_B = name_pair\n",
        "    # Generate a random place\n",
        "    place = random.choice(places)\n",
        "    # Generate a random object\n",
        "    objectA = random.choice(objects)\n",
        "    # Create a prompt\n",
        "    prompt = template.format(\n",
        "        name_A=name_A,\n",
        "        name_B=name_B,\n",
        "        place=place,\n",
        "        name_C=name_B,\n",
        "        object=objectA,\n",
        "    )\n",
        "    prompts.append(prompt)\n",
        "    name_pairs.append([name_A, name_B])\n",
        "\n",
        "    # generate flipped\n",
        "    prompt = template.format(\n",
        "        name_A=name_B,\n",
        "        name_B=name_A,\n",
        "        place=place,\n",
        "        name_C=name_B,\n",
        "        object=objectA,\n",
        "    )\n",
        "    prompts.append(prompt)\n",
        "    name_pairs.append([name_A, name_B])\n",
        "\n",
        "\n",
        "\n",
        "    # generate three other names that are not name_A and name_B\n",
        "    other_names = []\n",
        "    while(len(other_names) != 3):\n",
        "      new_name = random.choice(names)\n",
        "      if new_name is not name_A and new_name is not name_B and new_name not in other_names:\n",
        "        other_names.append(new_name)\n",
        "\n",
        "    counter_prompts.append(template.format(\n",
        "\n",
        "        name_A=other_names[0],\n",
        "        name_B=other_names[1],\n",
        "        place=place,\n",
        "        name_C=other_names[2],\n",
        "        object=objectA,\n",
        "\n",
        "    ))\n",
        "\n",
        "    counter_prompts.append(template.format(\n",
        "\n",
        "        name_A=other_names[1],\n",
        "        name_B=other_names[0],\n",
        "        place=place,\n",
        "        name_C=other_names[2],\n",
        "        object=objectA,\n",
        "\n",
        "    ))\n",
        "\n",
        "# Print the prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ED91qrlb6R5"
      },
      "outputs": [],
      "source": [
        "# generate random list of numbers\n",
        "rand_indices = torch.randint(0, len(prompts), size = (120,))\n",
        "\n",
        "# indices plus the indices + 1\n",
        "#double_rand_indices = torch.cat((rand_indices, rand_indices + 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUG9ASkwb6R5",
        "outputId": "4b153bde-39b0-4afe-e21d-fbf41d446645"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1835, 10442,  3861,  3465, 13260, 12180, 10593, 13039,  6659, 11697,\n",
              "         2553,  3157, 14881,   632,  2531, 13470, 13430, 15115,  5081,  2587,\n",
              "        15825, 12658, 15374,  3073, 10886,  6664, 17766,  1874, 18504,   233,\n",
              "         5879,  4125, 13286,  2426,  3492,  2785,  2942, 11549, 15381, 12000,\n",
              "        17930, 14765,  8676, 18795,   974, 19529, 12690,  1529, 10187,  1747,\n",
              "        11263,  3418, 12794, 15980, 15767,  2714,  6681,  1708, 13451, 18789,\n",
              "         7731,  7579,  8192,  7205, 15793,  2910, 12231,  2990,  8733, 14431,\n",
              "         4729, 17338, 10411,  4862,  9959,  3807, 15676, 18624, 12260,  8644,\n",
              "         6183,  2927, 14566,  1691,  3476, 11090, 19391, 14951,  9130, 11625,\n",
              "        15133,  7487, 10132, 15476,  5846, 11996,  6777, 15452, 11129,  5737,\n",
              "         2762, 19122,  1251,  6658,  6319,  7275, 13093,  9054,  2087,  6653,\n",
              "        19284, 15202,  4676,  2235,  2345, 17358,  8627,  3035,  2023, 11428])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "rand_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkaFniID2-t7"
      },
      "outputs": [],
      "source": [
        "clean_prompts = [prompts[i] for i in rand_indices]\n",
        "corrupted_prompts = [counter_prompts[i] for i in rand_indices]\n",
        "name_answers = [name_pairs[i] for i in rand_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOow7a593cZG"
      },
      "outputs": [],
      "source": [
        "clean_tokens = model.to_tokens(clean_prompts, prepend_bos = True).cuda()\n",
        "corrupted_tokens = model.to_tokens(corrupted_prompts, prepend_bos = True).cuda()\n",
        "answer_tokens = torch.concat([\n",
        "    model.to_tokens(names, prepend_bos=False).squeeze(dim=1).unsqueeze(dim=0) for names in name_answers\n",
        "]).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wdv6qRZ7cjL",
        "outputId": "106e9c61-c322-4333-d95d-eee9a96ec3d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([120, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "clean_tokens.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrNs-aafb6R6",
        "outputId": "a1818597-dca3-4156-a95b-91630bdce1e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('When Thomas and Josh went to the temple, Josh gave the jacket to',\n",
              " 'When Haley and Riley went to the temple, Cole gave the jacket to',\n",
              " [' Thomas', ' Josh'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "index = 1\n",
        "clean_prompts[index], corrupted_prompts[index], name_answers[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PzZDVgi3jwh"
      },
      "outputs": [],
      "source": [
        "model.reset_hooks()\n",
        "clean_logits, clean_cache = model.run_with_cache(clean_tokens, prepend_bos = False)\n",
        "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens, prepend_bos = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWjYCVbHfIP3"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCbedEz6xNZz"
      },
      "source": [
        "# chillin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHYwlc6rnmaH"
      },
      "outputs": [],
      "source": [
        "def logits_to_ave_logit_diff(\n",
        "    logits: Float[Tensor, \"batch seq d_vocab\"],\n",
        "    answer_tokens: Float[Tensor, \"batch 2\"] = answer_tokens,\n",
        "    per_prompt: bool = False\n",
        "):\n",
        "    '''\n",
        "    Returns logit difference between the correct and incorrect answer.\n",
        "\n",
        "    If per_prompt=True, return the array of differences rather than the average.\n",
        "    '''\n",
        "    # Only the final logits are relevant for the answer\n",
        "    final_logits: Float[Tensor, \"batch d_vocab\"] = logits[:, -1, :]\n",
        "    # Get the logits corresponding to the indirect object / subject tokens respectively\n",
        "    answer_logits: Float[Tensor, \"batch 2\"] = final_logits.gather(dim=-1, index=answer_tokens)\n",
        "    # Find logit difference\n",
        "    correct_logits, incorrect_logits = answer_logits.unbind(dim=-1)\n",
        "    answer_logit_diff = correct_logits - incorrect_logits\n",
        "    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw2AwkrQnpYz",
        "outputId": "f05faaff-ee90-4ba6-965f-caa0686d7148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.0976, device='cuda:0')\n",
            "tensor(0.2039, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "clean_per_prompt_diff = logits_to_ave_logit_diff(clean_logits, per_prompt = True)\n",
        "\n",
        "clean_average_logit_diff = logits_to_ave_logit_diff(clean_logits)\n",
        "corrupted_average_logit_diff = logits_to_ave_logit_diff(corrupted_logits)\n",
        "\n",
        "print(clean_average_logit_diff)\n",
        "print(corrupted_average_logit_diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es4GO_hnnum4"
      },
      "outputs": [],
      "source": [
        "answer_residual_directions: Float[Tensor, \"batch 2 d_model\"] = model.tokens_to_residual_directions(answer_tokens)\n",
        "correct_residual_direction, incorrect_residual_direction = answer_residual_directions.unbind(dim=1)\n",
        "logit_diff_directions: Float[Tensor, \"batch d_model\"] = correct_residual_direction - incorrect_residual_direction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vys_gX-soBi4"
      },
      "outputs": [],
      "source": [
        "def residual_stack_to_logit_diff(\n",
        "    residual_stack: Float[Tensor, \"... batch d_model\"],\n",
        "    cache: ActivationCache,\n",
        "    clean_cache = clean_cache,\n",
        "    logit_diff_directions: Float[Tensor, \"batch d_model\"] = logit_diff_directions,\n",
        "    use_clean_cache_for_LN = True\n",
        ") -> Float[Tensor, \"...\"]:\n",
        "    '''\n",
        "    Gets the avg logit difference between the correct and incorrect answer for a given\n",
        "    stack of components in the residual stream.\n",
        "    '''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    batch_size = residual_stack.size(-2)\n",
        "    if use_clean_cache_for_LN:\n",
        "      scaled_residual_stack = clean_cache.apply_ln_to_stack(residual_stack, layer=-1, pos_slice=-1)\n",
        "    else:\n",
        "      scaled_residual_stack = cache.apply_ln_to_stack(residual_stack, layer=-1, pos_slice=-1)\n",
        "\n",
        "\n",
        "\n",
        "    # # some extra code for more sanity checking\n",
        "    # new_logits = scaled_residual_stack @ model.W_U\n",
        "    # print(new_logits.shape)\n",
        "    # new_logits = einops.repeat(new_logits, \"batch d_vocab -> batch 1 d_vocab\")\n",
        "    # print(new_logits.shape)\n",
        "    # print(logits_to_ave_logit_diff(new_logits))\n",
        "\n",
        "    return einops.einsum(\n",
        "        scaled_residual_stack, logit_diff_directions,\n",
        "        \"... batch d_model, batch d_model -> ...\"\n",
        "    ) / batch_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1erVnl4Lqm_l",
        "outputId": "89912c95-d143-45d8-ca81-5eb5096590c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer residual directions shape: torch.Size([120, 2, 768])\n",
            "Logit difference directions shape: torch.Size([120, 768])\n"
          ]
        }
      ],
      "source": [
        "answer_residual_directions: Float[Tensor, \"batch 2 d_model\"] = model.tokens_to_residual_directions(answer_tokens)\n",
        "print(\"Answer residual directions shape:\", answer_residual_directions.shape)\n",
        "\n",
        "correct_residual_directions, incorrect_residual_directions = answer_residual_directions.unbind(dim=1)\n",
        "logit_diff_directions: Float[Tensor, \"batch d_model\"] = correct_residual_directions - incorrect_residual_directions\n",
        "print(f\"Logit difference directions shape:\", logit_diff_directions.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhTj_yJQb6R7",
        "outputId": "f83af84c-5775-485c-d3cc-a1c8a4b49cb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50257])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model.b_U.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKp2sOuqb6R7"
      },
      "outputs": [],
      "source": [
        "diff_from_unembedding_bias = model.b_U[answer_tokens[:, 0]] -  model.b_U[answer_tokens[:, 1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZIobMegqnJ5",
        "outputId": "08e119bb-21e0-4cfe-abb0-537915e43d75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final residual stream shape: torch.Size([120, 15, 768])\n",
            "Calculated average logit diff: 4.0975685120\n",
            "Original logit difference:     4.0975699425\n"
          ]
        }
      ],
      "source": [
        "final_residual_stream: Float[Tensor, \"batch seq d_model\"] = clean_cache[\"resid_post\", -1]\n",
        "print(f\"Final residual stream shape: {final_residual_stream.shape}\")\n",
        "final_token_residual_stream: Float[Tensor, \"batch d_model\"] = final_residual_stream[:, -1, :]\n",
        "\n",
        "print(f\"Calculated average logit diff: {(residual_stack_to_logit_diff(final_token_residual_stream, clean_cache, logit_diff_directions = logit_diff_directions) + diff_from_unembedding_bias.mean(0)):.10f}\") # <-- okay b_U exists... and matters\n",
        "print(f\"Original logit difference:     {clean_average_logit_diff:.10f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JATymEVNrxLW"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmcwuLTTTrhY"
      },
      "source": [
        "## Logit Diffs + Gather Important Heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v59wxgS3TnD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e73ef9-74c8-4cd1-ff04-8e97d1fe8444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tried to stack head results when they weren't cached. Computing head results now\n"
          ]
        }
      ],
      "source": [
        "def calc_all_logit_diffs(cache, use_clean_cache = True):\n",
        "  clean_per_head_residual, labels = cache.stack_head_results(layer = -1, return_labels = True, apply_ln = False) # per_head_residual.shape = heads batch seq_pos d_model\n",
        "  # also, for the worried, no, we're not missing the application of LN here since it gets applied in the below function call\n",
        "  per_head_logit_diff: Float[Tensor, \"batch head\"] = residual_stack_to_logit_diff(clean_per_head_residual[:, :, -1, :], cache, use_clean_cache_for_LN=use_clean_cache)\n",
        "\n",
        "  per_head_logit_diff = einops.rearrange(\n",
        "      per_head_logit_diff,\n",
        "      \"(layer head) ... -> layer head ...\",\n",
        "      layer=model.cfg.n_layers\n",
        "  )\n",
        "\n",
        "  correct_direction_per_head_logit: Float[Tensor, \"batch head\"] = residual_stack_to_logit_diff(clean_per_head_residual[:, :, -1, :], cache, logit_diff_directions = correct_residual_direction, use_clean_cache_for_LN=use_clean_cache)\n",
        "\n",
        "  correct_direction_per_head_logit = einops.rearrange(\n",
        "      correct_direction_per_head_logit,\n",
        "      \"(layer head) ... -> layer head ...\",\n",
        "      layer=model.cfg.n_layers\n",
        "  )\n",
        "\n",
        "  incorrect_direction_per_head_logit: Float[Tensor, \"batch head\"] = residual_stack_to_logit_diff(clean_per_head_residual[:, :, -1, :], cache, logit_diff_directions = incorrect_residual_direction, use_clean_cache_for_LN=use_clean_cache)\n",
        "\n",
        "  incorrect_direction_per_head_logit = einops.rearrange(\n",
        "      incorrect_direction_per_head_logit,\n",
        "      \"(layer head) ... -> layer head ...\",\n",
        "      layer=model.cfg.n_layers\n",
        "  )\n",
        "\n",
        "  return per_head_logit_diff, correct_direction_per_head_logit, incorrect_direction_per_head_logit\n",
        "\n",
        "per_head_logit_diff, correct_direction_per_head_logit, incorrect_direction_per_head_logit = calc_all_logit_diffs(clean_cache)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siL52OuCTtOT",
        "outputId": "c1d98e8d-3d13-4127-cc76-5448d55b571c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(9, 9), (9, 6), (10, 0), (10, 10), (10, 6)]\n"
          ]
        }
      ],
      "source": [
        "top_heads = []\n",
        "k = 5\n",
        "\n",
        "flattened_tensor = per_head_logit_diff.flatten().cpu()\n",
        "_, topk_indices = torch.topk(flattened_tensor, k)\n",
        "top_layer_arr, top_index_arr = np.unravel_index(topk_indices.numpy(), per_head_logit_diff.shape)\n",
        "\n",
        "for l, i in zip(top_layer_arr, top_index_arr):\n",
        "  top_heads.append((l,i))\n",
        "\n",
        "print(top_heads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x73NxlXQFEE",
        "outputId": "531f184f-3ab9-4fbc-d0b5-7afa38cdaa6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0104, -0.0194, -0.4581, -0.0163, -0.0086,  0.0101, -0.1054,  0.0147,\n",
              "         0.0354, -0.0077, -1.0141,  0.0351], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "per_head_logit_diff[11]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhdinJ7TT0hp",
        "outputId": "ae8c679a-4ce6-400a-a9d3-4a74dd865899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(8, 6), (10, 7), (11, 2), (11, 6), (11, 10)]\n"
          ]
        }
      ],
      "source": [
        "neg_heads = []\n",
        "neg_indices = torch.nonzero(torch.lt(per_head_logit_diff, -0.1))\n",
        "neg_heads_list = neg_indices.squeeze().tolist()\n",
        "for i in neg_heads_list:\n",
        "  neg_heads.append((i[0], i[1]))\n",
        "\n",
        "print(neg_heads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "iKr56ZcJug25",
        "outputId": "5f6d58fa-1d2d-4646-dba7-b443930956ab"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"7d2841cf-b408-4c75-b59d-ed2618f07620\" class=\"plotly-graph-div\" style=\"height:525px; width:1500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7d2841cf-b408-4c75-b59d-ed2618f07620\")) {                    Plotly.newPlot(                        \"7d2841cf-b408-4c75-b59d-ed2618f07620\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[-0.0026261317543685436,-0.0039010068867355585,-0.0023244733456522226,0.005312655586749315,0.0027569930534809828,0.002639347454532981,-0.006958025973290205,-0.0086358105763793,-0.003470652736723423,0.01175295002758503,-0.0022336854599416256,-0.006490920204669237],[-0.008534199558198452,-0.0029257575515657663,0.0026462385430932045,0.001959530171006918,0.0017895200289785862,0.005332127213478088,-0.001084326533600688,-0.017500154674053192,0.00320151774212718,-0.0032904483377933502,0.001332704327069223,0.013938608579337597],[0.008180170319974422,-0.009158148430287838,-0.004394812975078821,0.0037640391383320093,-0.005178069230169058,-0.0017208000645041466,0.00220261188223958,0.013321464881300926,0.011939319781959057,0.00043832213850691915,0.0019486877135932446,-0.004146133083850145],[-0.001228294800966978,-0.0008721555932424963,-0.00266115739941597,-0.004898030776530504,0.004081289283931255,-0.0012242741649970412,-0.00038422620855271816,0.00031090492848306894,0.00034303375286981463,-0.003092460799962282,0.005057618487626314,0.006019591819494963],[-0.007692938670516014,0.0013158073415979743,-0.0040710922330617905,0.0037846125196665525,0.0014269250677898526,-0.0014369699638336897,-0.00017030668095685542,0.0007037801551632583,0.0011864651460200548,0.0022388107609003782,-0.001072015380486846,0.001291561871767044],[-0.010954463854432106,-0.007419514935463667,-0.0004200324765406549,-0.0029244169127196074,-0.005077054724097252,0.0002551011857576668,0.0030875077936798334,-0.0030768245924264193,0.006646429188549519,0.009990368038415909,-0.016875486820936203,0.009000012651085854],[-0.01667775772511959,0.0003461906162556261,0.005269316956400871,0.0020854398608207703,-0.012756229378283024,0.005476244725286961,0.008501448668539524,0.0008883968694135547,-0.005370903294533491,-0.0017094281502068043,0.0009776127990335226,-0.006154784467071295],[-0.0004691672511398792,0.0015984488418325782,-0.002452209359034896,0.07553216814994812,-0.0011549374321475625,-0.02382919006049633,0.0053056590259075165,-0.0020179201383143663,-0.01680755242705345,0.19492033123970032,-4.767142308992334e-05,-0.010187248699367046],[0.014126748777925968,0.0009466689662076533,-0.041143227368593216,0.01220407709479332,0.0011269963579252362,-0.006574385799467564,-0.15054023265838623,0.005515245720744133,-0.027471860870718956,0.004507746547460556,0.2595456838607788,0.013156997971236706],[0.11295026540756226,-0.00024727373966015875,0.06551027297973633,0.008562052622437477,-0.03349737077951431,0.05917569249868393,1.5012527704238892,0.08406858891248703,0.05590251088142395,3.181016206741333,0.0030139428563416004,-0.01116690319031477],[0.723728597164154,0.19017939269542694,0.08209504187107086,0.03067607991397381,0.002000771462917328,0.0041797286830842495,0.4172710180282593,-1.9868309497833252,-0.004192786756902933,-0.0005232969997450709,0.5558896064758301,0.00395475747063756],[0.010354439727962017,-0.01940777152776718,-0.45812150835990906,-0.01626765727996826,-0.00858798436820507,0.01007809117436409,-0.10535480827093124,0.01467047818005085,0.03536783531308174,-0.007657630834728479,-1.014134407043457,0.03508459031581879]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003eLogit Contribution: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"1\",\"z\":[[-0.008506283164024353,-0.01408437266945839,-0.010792719200253487,0.02390296570956707,0.015285586006939411,0.012781054712831974,0.0572664774954319,0.00514024356380105,0.020336242392659187,-0.02977892942726612,0.05250401049852371,0.011637031100690365],[0.009536437690258026,0.0043285926803946495,0.014291301369667053,0.009442155249416828,0.01709851622581482,-0.036748163402080536,-0.003973833750933409,0.021735668182373047,-0.0008609423530288041,-0.010612603276968002,0.013112400658428669,0.02876950614154339],[0.04019298404455185,0.03023756481707096,0.006401507183909416,0.02695729024708271,-0.0021372174378484488,-0.005995227489620447,-0.03395375609397888,-0.006516729481518269,-0.00011156226537423208,-0.022355670109391212,-0.012230898253619671,-0.01600600965321064],[0.020785517990589142,-0.002096974290907383,0.018602434545755386,0.006406937260180712,-0.014531350694596767,0.0030513708479702473,0.0007027570391073823,-0.022337567061185837,0.01674555614590645,-0.0076483492739498615,-0.02363312616944313,0.033204302191734314],[-0.0018419810803607106,0.01964621990919113,-0.005391719285398722,-0.019847378134727478,-0.027416247874498367,-0.006661382038146257,0.020847821608185768,-0.05158848315477371,-0.0009741588728502393,0.018838847056031227,0.000283816218143329,0.015982208773493767],[0.0004557534120976925,0.009878845885396004,-0.002543448004871607,0.002986345672979951,-0.002258479129523039,0.03287322819232941,0.008348891511559486,-0.002524112816900015,0.02055143192410469,-0.045685578137636185,-0.0190011914819479,0.023348182439804077],[0.001166638219729066,0.009919620119035244,0.0035596233792603016,-0.00916391983628273,0.02166835218667984,-0.011647752486169338,-0.009459619410336018,-0.005231538787484169,-0.02963208220899105,0.03715744987130165,0.002033545169979334,0.03337889537215233],[0.029012981802225113,0.029644669964909554,0.009131239727139473,0.016397561877965927,-0.012819305062294006,0.011153437197208405,-0.10975656658411026,0.023394057527184486,0.0338955819606781,-0.019810445606708527,0.010701454244554043,0.11682993918657303],[0.012764543294906616,0.0031767990440130234,0.154490664601326,0.4221729636192322,0.026064027100801468,0.026913704350590706,0.47704923152923584,0.032744716852903366,0.053172748535871506,0.002999511081725359,-0.4239211976528168,0.2262854427099228],[0.15536263585090637,0.006225000135600567,0.1803566962480545,0.10522092878818512,0.1413147896528244,-0.14867541193962097,2.0033717155456543,0.04886675253510475,0.646668553352356,3.5737411975860596,-0.007606733124703169,0.14065666496753693],[1.3908207416534424,0.31017982959747314,0.7758132815361023,0.14675511419773102,0.04128405824303627,-0.007609475404024124,0.6228196620941162,-2.5347063541412354,0.010848965495824814,0.18821211159229279,0.8402655124664307,0.036141104996204376],[0.12722335755825043,0.2633315920829773,0.3714865446090698,0.3338249623775482,-0.08061918616294861,0.03650577366352081,0.24507160484790802,0.19849997758865356,0.22144237160682678,0.14398281276226044,-1.582289457321167,0.2365712672472]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003eLogit Contribution: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"2\",\"z\":[[-0.005880145356059074,-0.010183345526456833,-0.008468246087431908,0.018590306863188744,0.01252859178930521,0.010141698643565178,0.0642244964838028,0.01377604715526104,0.02380688674747944,-0.04153187945485115,0.05473770946264267,0.01812794990837574],[0.01807064190506935,0.0072543504647910595,0.011645047925412655,0.007482623681426048,0.015309003181755543,-0.04208029434084892,-0.002889506984502077,0.03923580422997475,-0.00406245980411768,-0.007322157267481089,0.011779680848121643,0.014830907806754112],[0.032012809067964554,0.03939571604132652,0.0107963215559721,0.023193253204226494,0.003040855750441551,-0.004274421371519566,-0.03615637123584747,-0.01983819156885147,-0.01205088198184967,-0.022793995216488838,-0.014179571531713009,-0.011859878897666931],[0.022013813257217407,-0.0012248136335983872,0.02126358635723591,0.01130496896803379,-0.01861264929175377,0.004275633953511715,0.0010869866237044334,-0.02264847420156002,0.01640252210199833,-0.004555892199277878,-0.028690744191408157,0.027184711769223213],[0.0058509670197963715,0.0183304101228714,-0.0013206214644014835,-0.02363199181854725,-0.028843170031905174,-0.005224408116191626,0.021018125116825104,-0.05229226127266884,-0.00216061994433403,0.01660003885626793,0.0013558288337662816,0.014690636657178402],[0.01141021866351366,0.017298361286520958,-0.002123419661074877,0.005910760257393122,0.002818579087033868,0.03261812776327133,0.005261382088065147,0.0005527159082703292,0.013905003666877747,-0.0556759312748909,-0.0021257204934954643,0.014348169788718224],[0.017844393849372864,0.009573427960276604,-0.0017097010277211666,-0.011249355971813202,0.03442458063364029,-0.0171239972114563,-0.01796107366681099,-0.006119936238974333,-0.024261170998215675,0.038866881281137466,0.0010559279471635818,0.039533670991659164],[0.029482146725058556,0.028046220541000366,0.011583448387682438,-0.059134598821401596,-0.011664366349577904,0.034982629120349884,-0.11506221443414688,0.025411980226635933,0.05070312321186066,-0.21473078429698944,0.010749129578471184,0.12701719999313354],[-0.0013621917460113764,0.002230130834504962,0.1956339031457901,0.40996885299682617,0.024937041103839874,0.03348805382847786,0.6275894641876221,0.027229472994804382,0.08064461499452591,-0.001508236862719059,-0.683466911315918,0.2131284475326538],[0.04241236671805382,0.006472272798418999,0.11484639346599579,0.096658855676651,0.17481215298175812,-0.2078510969877243,0.502118706703186,-0.03520184010267258,0.5907661318778992,0.39272502064704895,-0.010620681568980217,0.15182356536388397],[0.6670921444892883,0.1200004294514656,0.6937182545661926,0.11607903242111206,0.03928329423069954,-0.011789199896156788,0.20554861426353455,-0.547874927520752,0.015041756443679333,0.18873541057109833,0.2843758761882782,0.032186344265937805],[0.11686889827251434,0.2827393412590027,0.8296082019805908,0.3500925898551941,-0.07203119993209839,0.02642768993973732,0.35042643547058105,0.18382950127124786,0.18607455492019653,0.15164045989513397,-0.56815505027771,0.20148663222789764]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003eLogit Contribution: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.31999999999999995],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"},\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"},\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.33999999999999997,0.6599999999999999],\"matches\":\"x\",\"title\":{\"text\":\"Head\"},\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false,\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.6799999999999999,0.9999999999999999],\"matches\":\"x\",\"title\":{\"text\":\"Head\"},\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false,\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"annotations\":[{\"font\":{},\"showarrow\":false,\"text\":\"Logit Diff - 4.10\",\"x\":0.15999999999999998,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Correct Direction\",\"x\":0.49999999999999994,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Incorrect Direction\",\"x\":0.8399999999999999,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Logit Contribution\"}},\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Logit Contributions on Clean Dataset\"},\"width\":1500,\"margin\":{\"r\":100,\"l\":100}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7d2841cf-b408-4c75-b59d-ed2618f07620');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def display_all_logits(cache, title = \"Logit Contributions\", comparison = False, return_fig = False, logits = None):\n",
        "\n",
        "  a,b,c = calc_all_logit_diffs(cache)\n",
        "  if logits is not None:\n",
        "    ld = logits_to_ave_logit_diff(logits)\n",
        "  else:\n",
        "    ld = 0.00\n",
        "\n",
        "  if not comparison:\n",
        "    fig = imshow(\n",
        "        torch.stack([a,b,c]),\n",
        "        return_fig = True,\n",
        "        facet_col = 0,\n",
        "        facet_labels = [f\"Logit Diff - {ld:.2f}\", \"Correct Direction\", \"Incorrect Direction\"],\n",
        "        title=title,\n",
        "        labels={\"x\": \"Head\", \"y\": \"Layer\", \"color\": \"Logit Contribution\"},\n",
        "        #coloraxis=dict(colorbar_ticksuffix = \"%\"),\n",
        "        border=True,\n",
        "        width=1500,\n",
        "        margin={\"r\": 100, \"l\": 100}\n",
        "    )\n",
        "  else:\n",
        "\n",
        "    ca, cb, cc = calc_all_logit_diffs(clean_cache)\n",
        "    fig = imshow(\n",
        "        torch.stack([a, b, c, a - ca, b - cb, c - cc]),\n",
        "        return_fig = True,\n",
        "        facet_col = 0,\n",
        "        facet_labels = [f\"Logit Diff - {ld:.2f}\", \"Correct Direction\", \"Incorrect Direction\", \"Logit Diff Diff\", \"Correction Direction Diff\", \"Incorrect Direction Diff\"],\n",
        "        title=title,\n",
        "        labels={\"x\": \"Head\", \"y\": \"Layer\", \"color\": \"Logit Contribution\"},\n",
        "        #coloraxis=dict(colorbar_ticksuffix = \"%\"),\n",
        "        border=True,\n",
        "        width=1500,\n",
        "        margin={\"r\": 100, \"l\": 100}\n",
        "    )\n",
        "\n",
        "\n",
        "  if return_fig:\n",
        "    return fig\n",
        "  else:\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "\n",
        "fig = display_all_logits(clean_cache, title = \"Logit Contributions on Clean Dataset\", return_fig = True, logits = clean_logits)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg0QXfBAFCgz"
      },
      "outputs": [],
      "source": [
        "def stare_at_attention_and_head_pat(cache, layer_to_stare_at, head_to_isolate, display_corrupted_text = False, verbose = True, specific = False, specific_index = 0):\n",
        "  \"\"\"\n",
        "  given a cache from a run, displays the attention patterns of a layer, as well as printing out how much the model\n",
        "  attends to the S1, S2, and IO token\n",
        "  \"\"\"\n",
        "\n",
        "  tokenized_str_tokens = model.to_str_tokens(corrupted_tokens[0]) if display_corrupted_text else model.to_str_tokens(clean_tokens[0])\n",
        "  attention_patten = cache[\"pattern\", layer_to_stare_at]\n",
        "  print(f\"Layer {layer_to_stare_at} Head {head_to_isolate} Activation Patterns:\")\n",
        "\n",
        "\n",
        "  if not specific:\n",
        "    S1 = attention_patten.mean(0)[head_to_isolate][-1][2].item()\n",
        "    IO = attention_patten.mean(0)[head_to_isolate][-1][4].item()\n",
        "    S2 = attention_patten.mean(0)[head_to_isolate][-1][10].item()\n",
        "  else:\n",
        "    S1 = attention_patten[specific_index, head_to_isolate][-1][2].item()\n",
        "    IO = attention_patten[specific_index, head_to_isolate][-1][4].item()\n",
        "    S2 = attention_patten[specific_index, head_to_isolate][-1][10].item()\n",
        "\n",
        "\n",
        "  print(\"Attention on S1: \" + str(S1))\n",
        "  print(\"Attention on IO: \" + str(IO))\n",
        "  print(\"Attention on S2: \" + str(S2))\n",
        "  print(\"S1 + IO - S2 = \" + str(S1 + IO - S2))\n",
        "  print(\"S1 + S2 - IO = \" + str(S1 + S2 - IO))\n",
        "  print(\"S1 - IO - S2 = \" + str(S1 - S2 - IO))\n",
        "\n",
        "\n",
        "  if verbose:\n",
        "    display(cv.attention.attention_heads(\n",
        "      tokens=tokenized_str_tokens,\n",
        "      attention= attention_patten.mean(0) if not specific else attention_patten[specific_index],\n",
        "      #attention_head_names=[f\"L{layer_to_stare_at}H{i}\" for i in range(model.cfg.n_heads)],\n",
        "    ))\n",
        "  else:\n",
        "    print(attention_patten.mean(0).shape)\n",
        "\n",
        "    display(cv.attention.attention_patterns(\n",
        "      tokens=tokenized_str_tokens,\n",
        "      attention=attention_patten.mean(0)if not specific else attention_patten[specific_index],\n",
        "      attention_head_names=[f\"L{layer_to_stare_at} H{i}\" for i in range(model.cfg.n_heads)],\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvBeXMV8Betp"
      },
      "outputs": [],
      "source": [
        "def display_corrupted_clean_logits(cache, title = \"Logit Contributions\", comparison = False, return_fig = False, logits = None):\n",
        "\n",
        "  a,b,c = calc_all_logit_diffs(cache)\n",
        "  if logits is not None:\n",
        "    ld = logits_to_ave_logit_diff(logits)\n",
        "  else:\n",
        "    ld = 0.00\n",
        "\n",
        "  if not comparison:\n",
        "    fig = imshow(\n",
        "        torch.stack([a]),\n",
        "        return_fig = True,\n",
        "        facet_col = 0,\n",
        "        facet_labels = [f\"Logit Diff - {ld:.2f}\"],\n",
        "        title=title,\n",
        "        labels={\"x\": \"Head\", \"y\": \"Layer\", \"color\": \"Logit Contribution\"},\n",
        "        #coloraxis=dict(colorbar_ticksuffix = \"%\"),\n",
        "        border=True,\n",
        "        width=1500,\n",
        "        margin={\"r\": 100, \"l\": 100}\n",
        "    )\n",
        "  else:\n",
        "\n",
        "    ca, cb, cc = calc_all_logit_diffs(clean_cache)\n",
        "    fig = imshow(\n",
        "        torch.stack([a, ca, a - ca]),\n",
        "        return_fig = True,\n",
        "        facet_col = 0,\n",
        "        facet_labels = [f\"Ablated Logit Differences: {ld:.2f}\", f\"Clean Logit Differences: {clean_average_logit_diff:.2f}\", f\"Difference between Ablated and Clea: {(ld - clean_average_logit_diff):.2f}\",],\n",
        "        title=title,\n",
        "        labels={\"x\": \"Head\", \"y\": \"Layer\", \"color\": \"Logit Contribution\"},\n",
        "        #coloraxis=dict(colorbar_ticksuffix = \"%\"),\n",
        "        border=True,\n",
        "        width=1000,\n",
        "        margin={\"r\": 100, \"l\": 100}\n",
        "    )\n",
        "\n",
        "\n",
        "  if return_fig:\n",
        "    return fig\n",
        "  else:\n",
        "    fig.show()\n",
        "\n",
        "    return a - ca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "IfRvIIAPBHAy",
        "outputId": "6cc68037-002f-4c6c-ea83-288996a3e167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tried to stack head results when they weren't cached. Computing head results now\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"5e9124ee-4666-4820-ab24-a220cb0f63db\" class=\"plotly-graph-div\" style=\"height:525px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5e9124ee-4666-4820-ab24-a220cb0f63db\")) {                    Plotly.newPlot(                        \"5e9124ee-4666-4820-ab24-a220cb0f63db\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[-0.0026261317543685436,-0.0039010068867355585,-0.0023244733456522226,0.005312655586749315,0.0027569930534809828,0.002639347454532981,-0.006958025973290205,-0.0086358105763793,-0.003470652736723423,0.01175295002758503,-0.0022336854599416256,-0.006490920204669237],[-0.008534199558198452,-0.0029257575515657663,0.0026462385430932045,0.001959530171006918,0.0017895200289785862,0.005332127213478088,-0.001084326533600688,-0.017500154674053192,0.00320151774212718,-0.0032904483377933502,0.001332704327069223,0.013938608579337597],[0.008180170319974422,-0.009158148430287838,-0.004394812975078821,0.0037640391383320093,-0.005178069230169058,-0.0017208000645041466,0.00220261188223958,0.013321464881300926,0.011939319781959057,0.00043832213850691915,0.0019486877135932446,-0.004146133083850145],[-0.001228294800966978,-0.0008721555932424963,-0.00266115739941597,-0.004898030776530504,0.004081289283931255,-0.0012242741649970412,-0.00038422620855271816,0.00031090492848306894,0.00034303375286981463,-0.003092460799962282,0.005057618487626314,0.006019591819494963],[-0.007692938670516014,0.0013158073415979743,-0.0040710922330617905,0.0037846125196665525,0.0014269250677898526,-0.0014369699638336897,-0.00017030668095685542,0.0007037801551632583,0.0011864651460200548,0.0022388107609003782,-0.001072015380486846,0.001291561871767044],[-0.010954463854432106,-0.007419514935463667,-0.0004200324765406549,-0.0029244169127196074,-0.005077054724097252,0.0002551011857576668,0.0030875077936798334,-0.0030768245924264193,0.006646429188549519,0.009990368038415909,-0.016875486820936203,0.009000012651085854],[-0.01667775772511959,0.0003461906162556261,0.005269316956400871,0.0020854398608207703,-0.012756229378283024,0.005476244725286961,0.008501448668539524,0.0008883968694135547,-0.005370903294533491,-0.0017094281502068043,0.0009776127990335226,-0.006154784467071295],[-0.0004691672511398792,0.0015984488418325782,-0.002452209359034896,0.07553216814994812,-0.0011549374321475625,-0.02382919006049633,0.0053056590259075165,-0.0020179201383143663,-0.01680755242705345,0.19492033123970032,-4.767142308992334e-05,-0.010187248699367046],[0.014126748777925968,0.0009466689662076533,-0.041143227368593216,0.01220407709479332,0.0011269963579252362,-0.006574385799467564,-0.15054023265838623,0.005515245720744133,-0.027471860870718956,0.004507746547460556,0.2595456838607788,0.013156997971236706],[0.11295026540756226,-0.00024727373966015875,0.06551027297973633,0.008562052622437477,-0.03349737077951431,0.05917569249868393,0.026338061317801476,0.08406858891248703,0.05590251088142395,-0.01174671109765768,0.0030139428563416004,-0.01116690319031477],[0.049564387649297714,0.4218606948852539,0.7474797368049622,0.081412672996521,0.001892576110549271,0.0030474599916487932,0.8228524327278137,0.18375808000564575,-0.004719851538538933,-0.007152595557272434,1.2934128046035767,0.009651069529354572],[0.008705920539796352,0.0456402488052845,0.23407086730003357,0.07801829278469086,-0.009426241740584373,0.0075720432214438915,-0.03165315091609955,0.015132838860154152,0.028524789959192276,0.09220913797616959,-1.115452766418457,0.07126633077859879]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003eLogit Contribution: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"1\",\"z\":[[-0.0026261317543685436,-0.0039010068867355585,-0.0023244733456522226,0.005312655586749315,0.0027569930534809828,0.002639347454532981,-0.006958025973290205,-0.0086358105763793,-0.003470652736723423,0.01175295002758503,-0.0022336854599416256,-0.006490920204669237],[-0.008534199558198452,-0.0029257575515657663,0.0026462385430932045,0.001959530171006918,0.0017895200289785862,0.005332127213478088,-0.001084326533600688,-0.017500154674053192,0.00320151774212718,-0.0032904483377933502,0.001332704327069223,0.013938608579337597],[0.008180170319974422,-0.009158148430287838,-0.004394812975078821,0.0037640391383320093,-0.005178069230169058,-0.0017208000645041466,0.00220261188223958,0.013321464881300926,0.011939319781959057,0.00043832213850691915,0.0019486877135932446,-0.004146133083850145],[-0.001228294800966978,-0.0008721555932424963,-0.00266115739941597,-0.004898030776530504,0.004081289283931255,-0.0012242741649970412,-0.00038422620855271816,0.00031090492848306894,0.00034303375286981463,-0.003092460799962282,0.005057618487626314,0.006019591819494963],[-0.007692938670516014,0.0013158073415979743,-0.0040710922330617905,0.0037846125196665525,0.0014269250677898526,-0.0014369699638336897,-0.00017030668095685542,0.0007037801551632583,0.0011864651460200548,0.0022388107609003782,-0.001072015380486846,0.001291561871767044],[-0.010954463854432106,-0.007419514935463667,-0.0004200324765406549,-0.0029244169127196074,-0.005077054724097252,0.0002551011857576668,0.0030875077936798334,-0.0030768245924264193,0.006646429188549519,0.009990368038415909,-0.016875486820936203,0.009000012651085854],[-0.01667775772511959,0.0003461906162556261,0.005269316956400871,0.0020854398608207703,-0.012756229378283024,0.005476244725286961,0.008501448668539524,0.0008883968694135547,-0.005370903294533491,-0.0017094281502068043,0.0009776127990335226,-0.006154784467071295],[-0.0004691672511398792,0.0015984488418325782,-0.002452209359034896,0.07553216814994812,-0.0011549374321475625,-0.02382919006049633,0.0053056590259075165,-0.0020179201383143663,-0.01680755242705345,0.19492033123970032,-4.767142308992334e-05,-0.010187248699367046],[0.014126748777925968,0.0009466689662076533,-0.041143227368593216,0.01220407709479332,0.0011269963579252362,-0.006574385799467564,-0.15054023265838623,0.005515245720744133,-0.027471860870718956,0.004507746547460556,0.2595456838607788,0.013156997971236706],[0.11295026540756226,-0.00024727373966015875,0.06551027297973633,0.008562052622437477,-0.03349737077951431,0.05917569249868393,1.5012527704238892,0.08406858891248703,0.05590251088142395,3.181016206741333,0.0030139428563416004,-0.01116690319031477],[0.723728597164154,0.19017939269542694,0.08209504187107086,0.03067607991397381,0.002000771462917328,0.0041797286830842495,0.4172710180282593,-1.9868309497833252,-0.004192786756902933,-0.0005232969997450709,0.5558896064758301,0.00395475747063756],[0.010354439727962017,-0.01940777152776718,-0.45812150835990906,-0.01626765727996826,-0.00858798436820507,0.01007809117436409,-0.10535480827093124,0.01467047818005085,0.03536783531308174,-0.007657630834728479,-1.014134407043457,0.03508459031581879]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003eLogit Contribution: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"2\",\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,-1.4749146699905396,0.0,0.0,-3.192762851715088,0.0,0.0],[-0.6741642355918884,0.23168130218982697,0.6653847098350525,0.05073659121990204,-0.00010819535236805677,-0.0011322686914354563,0.40558141469955444,2.170588970184326,-0.0005270647816359997,-0.0066292984411120415,0.7375231981277466,0.005696312058717012],[-0.0016485191881656647,0.06504802405834198,0.6921923756599426,0.09428595006465912,-0.000838257372379303,-0.0025060479529201984,0.0737016573548317,0.000462360680103302,-0.006843045353889465,0.09986677020788193,-0.101318359375,0.03618174046278]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003eLogit Contribution: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.31999999999999995],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"},\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"},\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.33999999999999997,0.6599999999999999],\"matches\":\"x\",\"title\":{\"text\":\"Head\"},\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false,\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.6799999999999999,0.9999999999999999],\"matches\":\"x\",\"title\":{\"text\":\"Head\"},\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false,\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"annotations\":[{\"font\":{},\"showarrow\":false,\"text\":\"Ablated Logit Differences: 4.12\",\"x\":0.15999999999999998,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Clean Logit Differences: 4.10\",\"x\":0.49999999999999994,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Difference between Ablated and Clea: 0.02\",\"x\":0.8399999999999999,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Logit Contribution\"}},\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Logit Differences When Sample Ablating in Name Mover Heads\"},\"width\":1000,\"margin\":{\"r\":100,\"l\":100}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5e9124ee-4666-4820-ab24-a220cb0f63db');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "heads =  [(9,9), (9,6), (10,0)]\n",
        "model.reset_hooks() # callum library buggy\n",
        "def return_item(item):\n",
        "  return item\n",
        "\n",
        "model.reset_hooks()\n",
        "patched_logits = act_patch(\n",
        "    model = model,\n",
        "    orig_input = clean_tokens,\n",
        "    new_cache = corrupted_cache,\n",
        "    patching_nodes = [Node(\"z\", layer = layer, head = head) for layer, head in heads],\n",
        "    patching_metric = return_item,\n",
        "    verbose = False,\n",
        "    apply_metric_to_cache = False\n",
        ")\n",
        "\n",
        "model.reset_hooks()\n",
        "noise_sample_ablating_results = act_patch(\n",
        "    model = model,\n",
        "    orig_input = clean_tokens,\n",
        "    new_cache = corrupted_cache,\n",
        "    patching_nodes = [Node(\"z\", layer = layer, head = head) for layer, head in heads],\n",
        "    patching_metric = partial(display_corrupted_clean_logits, title = f\"Logit Differences When Sample Ablating in Name Mover Heads\", comparison = True, logits = patched_logits),\n",
        "    verbose = False,\n",
        "    apply_metric_to_cache = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "680GmxIhgu-6"
      },
      "source": [
        "#  Graph Figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIPoWHIF4vuy"
      },
      "outputs": [],
      "source": [
        "heads =  [(9,i) for i in range(12)] +  [(10,i) for i in range(12)]\n",
        "model.reset_hooks() # callum library buggy\n",
        "def return_item(item):\n",
        "  return item\n",
        "\n",
        "model.reset_hooks()\n",
        "patched_logits = act_patch(\n",
        "    model = model,\n",
        "    orig_input = clean_tokens,\n",
        "    new_cache = corrupted_cache,\n",
        "    patching_nodes = [Node(\"z\", layer = layer, head = head) for layer, head in heads],\n",
        "    patching_metric = return_item,\n",
        "    verbose = False,\n",
        "    apply_metric_to_cache = False\n",
        ")\n",
        "\n",
        "model.reset_hooks()\n",
        "all_layernine_noise_patching_results = act_patch(\n",
        "    model = model,\n",
        "    orig_input = clean_tokens,\n",
        "    new_cache = corrupted_cache,\n",
        "    patching_nodes = [Node(\"z\", layer = layer, head = head) for layer, head in heads],\n",
        "    patching_metric = partial(display_corrupted_clean_logits, title = f\"Logits When Sample Ablating in Layer 9\", comparison = True, logits = patched_logits),\n",
        "    verbose = False,\n",
        "    apply_metric_to_cache = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyLYSz9Lg6Y2"
      },
      "outputs": [],
      "source": [
        "layer_nine_patching_NMHs = act_patch(\n",
        "    model = model,\n",
        "    orig_input = clean_tokens,\n",
        "    new_cache = corrupted_cache,\n",
        "    patching_nodes = [Node(\"z\", layer = 9 , head = 6) , Node(\"z\", layer = 9 , head = 9)],\n",
        "    patching_metric = return_item,\n",
        "    verbose = False,\n",
        "    apply_metric_to_cache = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ4gXEuihB1r"
      },
      "outputs": [],
      "source": [
        "ablated_logit_diff,_,_ = calc_all_logit_diffs(layer_nine_patching_NMHs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAD6pOBUlxUJ"
      },
      "outputs": [],
      "source": [
        "neg_m_heads = [(10,7), (11,10)]\n",
        "name_mover_heads = [(9,9), (9,6), (10,0)]\n",
        "backup_heads = [(9,0), (9,7), (10,1), (10,2), (10,6), (10,10), (11,2), (11,9)]\n",
        "key_backup_heads = [(10,2), (10,6), (10,10), (11,2)]\n",
        "strong_neg_backup_heads = [(11,2), (10,2), (10,0), (11,6)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jGNJPv6iOrq"
      },
      "outputs": [],
      "source": [
        "heads_to_name = neg_m_heads + [(10,0)] + key_backup_heads\n",
        "fig_names = [str((i,j)) for i in range(12) for j in range(12)]\n",
        "for i in range(12):\n",
        "  for j in range(12):\n",
        "    if fig_names[i * 12 + j] not in [str(i) for i in heads_to_name]:\n",
        "      fig_names[i * 12 + j] = None\n",
        "    else:\n",
        "      fig_names[i * 12 + j] = str(i) + \".\" + str(j)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvZAAScphKkQ"
      },
      "outputs": [],
      "source": [
        "x =  per_head_logit_diff.flatten()\n",
        "y =  ablated_logit_diff.flatten()\n",
        "\n",
        "\n",
        "fig = px.scatter()\n",
        "\n",
        "fig.add_trace(go.Scatter(x = x.cpu(), y = y.cpu(), text = fig_names, textposition=\"top center\", mode = 'markers+text', name = \"gpt-2\"))\n",
        "\n",
        "x_range = np.linspace(start=min(fig.data[1].x) - 0.5, stop=max(fig.data[1].x) + 0.5, num=100)\n",
        "fig.add_trace(go.Scatter(x=x_range, y=x_range, mode='lines', name='y=x', line_color = \"black\", ))\n",
        "fig.update_xaxes(title = \"Clean Logit Difference\")\n",
        "fig.update_yaxes(title = \"Post-Intervention Logit Difference\")\n",
        "fig.update_layout(title = \"Logit Differences When Sample Ablating in Layer 9 Name Mover Heads\", width = 950)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbEZcM3Le0j1"
      },
      "outputs": [],
      "source": [
        "# save fig as pdf\n",
        "fig.write_image(\"ldd_sample_ablation.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using path patching instead\n",
        "\n",
        "path_patch_lds = torch.zeros((12,12))\n",
        "for layer in range(12):\n",
        "  for head in range(12):\n",
        "    temp_cache = path_patch(\n",
        "        model,\n",
        "        orig_input = clean_tokens,\n",
        "        new_cache = corrupted_cache,\n",
        "        sender_nodes = [Node(\"z\", layer = 9 , head = 6) , Node(\"z\", layer = 9 , head = 9), Node(\"z\", layer = 10, head = 0)],\n",
        "        receiver_nodes = [Node(\"q\", layer = layer, head = head), Node(\"k\", layer = layer, head = head), Node(\"v\", layer = layer, head = head)],\n",
        "        apply_metric_to_cache = True,\n",
        "        patching_metric = return_item,\n",
        "    )\n",
        "\n",
        "    path_patch_lds[layer, head] = calc_all_logit_diffs(temp_cache, True)[0][layer, head]"
      ],
      "metadata": {
        "id": "jwmIgzBFgl2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x =  per_head_logit_diff.flatten()\n",
        "y =  path_patch_lds.flatten()\n",
        "\n",
        "\n",
        "fig = px.scatter()\n",
        "\n",
        "fig.add_trace(go.Scatter(x = x.cpu(), y = y.cpu(), text = fig_names, textposition=\"top center\", mode = 'markers+text', name = \"gpt-2\"))\n",
        "\n",
        "x_range = np.linspace(start=min(fig.data[1].x) - 0.5, stop=max(fig.data[1].x) + 0.5, num=100)\n",
        "fig.add_trace(go.Scatter(x=x_range, y=x_range, mode='lines', name='y=x', line_color = \"black\", ))\n",
        "fig.update_xaxes(title = \"Clean Logit Difference\")\n",
        "fig.update_yaxes(title = \"Post-Intervention Logit Difference\")\n",
        "fig.update_layout(title = \"Logit Differences When Path Patching from Name Mover Heads into Downstream Heads\", width = 950)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "r1nl5f5Vi0Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PacI0bEdjHtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save fig as pdf\n",
        "fig.write_image(\"ldd_path_patching.pdf\")"
      ],
      "metadata": {
        "id": "-GTX9Ko1jEtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save fig as pdf\n",
        "fig.write_image(\"ldd_path_patching_2.pdf\")"
      ],
      "metadata": {
        "id": "5VjbN9wLkYt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtGaksXue0j1"
      },
      "source": [
        "## Figures: How much does Negative Heads explain Self-Repair?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2LtsC1Ze0j2"
      },
      "outputs": [],
      "source": [
        "cache_patching_NMHs = act_patch(\n",
        "    model = model,\n",
        "    orig_input = clean_tokens,\n",
        "    new_cache = corrupted_cache,\n",
        "    patching_nodes = [Node(\"z\", layer = 9 , head = 6) , Node(\"z\", layer = 9 , head = 9), Node(\"z\", layer = 10 , head = 0)],\n",
        "    patching_metric = return_item,\n",
        "    verbose = False,\n",
        "    apply_metric_to_cache = True\n",
        ")\n",
        "\n",
        "patched_NMHs_logit_diff ,_,_ = calc_all_logit_diffs(cache_patching_NMHs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvnOr5-Ye0j2"
      },
      "outputs": [],
      "source": [
        "patched_NMHS_backup = patched_NMHs_logit_diff - per_head_logit_diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_FPz-F1e0j2"
      },
      "outputs": [],
      "source": [
        "# sum over last two layers of backup, but not including 10.0\n",
        "\n",
        "last_two_layer_diff = patched_NMHS_backup.flatten().sum() - patched_NMHS_backup[10, 0] - patched_NMHS_backup[9,9] - patched_NMHS_backup[9,6]\n",
        "sum_from_negative = patched_NMHS_backup[10, 7] + patched_NMHS_backup[11,10]\n",
        "neg_head_backup_amount = sum_from_negative / last_two_layer_diff\n",
        "print(neg_head_backup_amount)\n",
        "print(last_two_layer_diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJPsgB35e0j2"
      },
      "outputs": [],
      "source": [
        "sum_from_negative / last_two_layer_diff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnOqH2XMgznE"
      },
      "source": [
        "# Normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5ezr2iwpz7m"
      },
      "outputs": [],
      "source": [
        "neg_m_heads = [(10,7), (11,10)]\n",
        "name_mover_heads = [(9,9), (9,6), (10,0)]\n",
        "backup_heads = [(9,0), (9,7), (10,1), (10,2), (10,6), (10,10), (11,2), (11,9)]\n",
        "key_backup_heads = [(10,2), (10,6), (10,10), (11,2)]\n",
        "strong_neg_backup_heads = [(11,2), (10,2), (10,0), (11,6)]\n",
        "\n",
        "\n",
        "\n",
        "head_names = [\"Negative\", \"Name Mover\", \"Backup\"]\n",
        "head_list = [neg_m_heads, name_mover_heads, backup_heads]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uLaAF0Qb6R9"
      },
      "outputs": [],
      "source": [
        "def noising_ioi_metric(\n",
        "    logits: Float[Tensor, \"batch seq d_vocab\"],\n",
        "    clean_logit_diff: float = clean_average_logit_diff,\n",
        "    corrupted_logit_diff: float = corrupted_average_logit_diff,\n",
        ") -> float:\n",
        "    '''\n",
        "    Given logits, returns how much the performance has been corrupted due to noising.\n",
        "\n",
        "    We calibrate this so that the value is 0 when performance isn't harmed (i.e. same as IOI dataset),\n",
        "    and -1 when performance has been destroyed (i.e. is same as ABC dataset).\n",
        "    '''\n",
        "    #print(logits[-1, -1])\n",
        "    patched_logit_diff = logits_to_ave_logit_diff(logits)\n",
        "    return ((patched_logit_diff - clean_logit_diff) / (clean_logit_diff - corrupted_logit_diff))\n",
        "\n",
        "print(f\"IOI metric (IOI dataset): {noising_ioi_metric(clean_logits):.4f}\")\n",
        "print(f\"IOI metric (ABC dataset): {noising_ioi_metric(corrupted_logits):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Wx9Xggsb6R-"
      },
      "outputs": [],
      "source": [
        "def denoising_ioi_metric(\n",
        "    logits: Float[Tensor, \"batch seq d_vocab\"],\n",
        "    clean_logit_diff: float = clean_average_logit_diff,\n",
        "    corrupted_logit_diff: float = corrupted_average_logit_diff,\n",
        ") -> float:\n",
        "    '''\n",
        "    We calibrate this so that the value is 1 when performance got restored (i.e. same as IOI dataset),\n",
        "    and 0 when performance has been destroyed (i.e. is same as ABC dataset).\n",
        "    '''\n",
        "    patched_logit_diff = logits_to_ave_logit_diff(logits)\n",
        "    return ((patched_logit_diff - clean_logit_diff) / (clean_logit_diff - corrupted_logit_diff) + 1)\n",
        "\n",
        "\n",
        "print(f\"IOI metric (IOI dataset): {denoising_ioi_metric(clean_logits):.4f}\")\n",
        "print(f\"IOI metric (ABC dataset): {denoising_ioi_metric(corrupted_logits):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-n1WgQ3wI42"
      },
      "source": [
        "## Query Intervention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbaPrch3wUe_"
      },
      "outputs": [],
      "source": [
        "def store_activation(\n",
        "    activation,\n",
        "    hook: HookPoint,\n",
        "    where_to_store\n",
        "):\n",
        "    \"\"\"\n",
        "    takes a storage container where_to_store, and stores the activation in it at a hook\n",
        "    \"\"\"\"\"\n",
        "    where_to_store[:] = activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEivke9cwRFL"
      },
      "outputs": [],
      "source": [
        "def kq_rewrite_hook(\n",
        "    internal_value: Float[Tensor, \"batch seq head d_head\"],\n",
        "    hook: HookPoint,\n",
        "    head,\n",
        "    unnormalized_resid:  Float[Tensor, \"batch seq d_model\"],\n",
        "    vector,\n",
        "    act_name,\n",
        "    scale = 1,\n",
        "    position = -1,\n",
        "    pre_ln = True\n",
        "):\n",
        "  \"\"\"\n",
        "  replaces keys or queries with a new result which we get from adding a vector to a position at the residual stream\n",
        "  head: tuple for head to rewrite keys for\n",
        "  unnormalized_resid: stored unnormalized residual stream needed to recalculated activations\n",
        "  \"\"\"\n",
        "\n",
        "  ln1 = model.blocks[hook.layer()].ln1\n",
        "  temp_resid = unnormalized_resid.clone()\n",
        "\n",
        "  if pre_ln:\n",
        "    temp_resid[:, position, :] = temp_resid[:, position, :] + scale * vector\n",
        "    normalized_resid = ln1(temp_resid)\n",
        "  else:\n",
        "    temp_resid = ln1(temp_resid)\n",
        "    temp_resid[:, position, :] = temp_resid[:, position, :] + scale * vector\n",
        "    normalized_resid = temp_resid\n",
        "\n",
        "\n",
        "  assert act_name == \"q\" or act_name == \"k\"\n",
        "  if act_name == \"q\":\n",
        "    W_Q, b_Q = model.W_Q[head[0], head[1]], model.b_Q[head[0], head[1]]\n",
        "    internal_value[..., head[1], :] = einops.einsum(normalized_resid, W_Q, \"batch seq d_model, d_model d_head -> batch seq d_head\") + b_Q\n",
        "\n",
        "  elif act_name == \"k\":\n",
        "    W_K, b_K = model.W_K[head[0], head[1]], model.b_K[head[0], head[1]]\n",
        "    internal_value[..., head[1], :] = einops.einsum(normalized_resid, W_K, \"batch seq d_model, d_model d_head -> batch seq d_head\") + b_K\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBYtXCAUwT3b"
      },
      "outputs": [],
      "source": [
        "def patch_head_vector(\n",
        "    head_vector: Float[Tensor, \"batch pos head_index d_head\"],\n",
        "    hook: HookPoint,\n",
        "    head_indices: int,\n",
        "    other_cache: ActivationCache\n",
        ") -> Float[Tensor, \"batch pos head_index d_head\"]:\n",
        "    '''\n",
        "    Patches the output of a given head (before it's added to the residual stream) at\n",
        "    every sequence position, using the value from the other cache.\n",
        "    '''\n",
        "    for head_index in head_indices:\n",
        "      head_vector[:, :, head_index] = other_cache[hook.name][:, :, head_index]\n",
        "    return head_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7QGFDu3TgyS"
      },
      "outputs": [],
      "source": [
        "def patch_ln_scale(ln_scale, hook):\n",
        "  #print(torch.equal(ln_scale, clean_cache[\"blocks.\" + str(hook.layer()) + \".ln1.hook_scale\"]))\n",
        "  ln_scale = clean_cache[\"blocks.\" + str(hook.layer()) + \".ln1.hook_scale\"]\n",
        "  return ln_scale\n",
        "\n",
        "\n",
        "def patch_ln2_scale(ln_scale, hook):\n",
        "  #print(torch.equal(ln_scale, clean_cache[\"blocks.\" + str(hook.layer()) + \".ln1.hook_scale\"]))\n",
        "  ln_scale = clean_cache[\"blocks.\" + str(hook.layer()) + \".ln2.hook_scale\"]\n",
        "  return ln_scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDlAHwPHwZx8"
      },
      "outputs": [],
      "source": [
        "def causal_write_into_component(act_comp, head, direction, x, pre_ln = True, result_cache_function = None, result_cache_fun_has_head_input = False, freeze_layernorm = False, ablate_heads = []):\n",
        "  '''\n",
        "  writes a vector into the component at a given head\n",
        "  returns new logit differences of run by default, or pass result_cache_funciton to run on cache\n",
        "\n",
        "  head - tuple for head to intervene in act_comp for\n",
        "  direction - vector to add to the act_comp in the head\n",
        "  x - tensor of amount to scale\n",
        "  '''\n",
        "  y = torch.zeros(x.shape)\n",
        "  for i in range(len(x)):\n",
        "    scale = x[i]\n",
        "    model.reset_hooks()\n",
        "    temp = torch.zeros((batch_size, seq_len, model.cfg.d_model)).cuda()\n",
        "    model.add_hook(utils.get_act_name(\"resid_pre\", head[0]), partial(store_activation, where_to_store = temp))\n",
        "    if freeze_layernorm:\n",
        "      model.add_hook(\"blocks.\" + str(head[0]) + \".ln1.hook_scale\", patch_ln_scale)\n",
        "    model.add_hook(utils.get_act_name(act_comp, head[0]), partial(kq_rewrite_hook, head = head, unnormalized_resid = temp, vector = direction, act_name = act_comp, scale = scale, pre_ln = pre_ln))\n",
        "\n",
        "\n",
        "    if len(ablate_heads) != 0:\n",
        "      for j in ablate_heads:\n",
        "        model.add_hook(utils.get_act_name(\"z\", j[0]), partial(patch_head_vector, head_indices = [j[1]], other_cache = corrupted_cache))\n",
        "\n",
        "\n",
        "    hooked_logits, hooked_cache = model.run_with_cache(clean_tokens)\n",
        "    model.reset_hooks()\n",
        "\n",
        "\n",
        "    if result_cache_function != None:\n",
        "      if not result_cache_fun_has_head_input:\n",
        "        y[i] = result_cache_function(hooked_cache)\n",
        "      else:\n",
        "        y[i] = result_cache_function(hooked_cache, head)\n",
        "    else:\n",
        "      # just calculate logit diff\n",
        "      y[i] = logits_to_ave_logit_diff(hooked_logits)\n",
        "\n",
        "  return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_q21PDbyo2R"
      },
      "outputs": [],
      "source": [
        "def graph_lines(results, heads, x, title = \"Effect of adding/subtracting direction\", xtitle = \"Scaling on direction\", ytitle = \"Logit Diff\"):\n",
        "  fig = px.line(title = title)\n",
        "  for i in range(len(results)):\n",
        "    fig.add_trace(go.Scatter(x = x, y = results[i], name = str(heads[i])))\n",
        "\n",
        "  fig.update_xaxes(title = xtitle)\n",
        "  fig.update_yaxes(title = ytitle)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YNnE8De8lPY"
      },
      "outputs": [],
      "source": [
        "def get_head_IO_minus_S_attn(cache, head, scores = True):\n",
        "\n",
        "  layer, h_index = head\n",
        "\n",
        "  if scores:\n",
        "    attention_patten = cache[\"attn_scores\", layer]\n",
        "  else:\n",
        "    attention_patten = cache[\"pattern\", layer]\n",
        "  S1 = attention_patten.mean(0)[h_index][-1][2].item()\n",
        "  IO = attention_patten.mean(0)[h_index][-1][4].item()\n",
        "  S2 = attention_patten.mean(0)[h_index][-1][10].item()\n",
        "\n",
        "  return IO - S1 - S2\n",
        "\n",
        "\n",
        "def get_head_IO_minus_just_S1_attn(cache, head, scores = True):\n",
        "\n",
        "    layer, h_index = head\n",
        "\n",
        "    if scores:\n",
        "      attention_patten = cache[\"attn_scores\", layer]\n",
        "    else:\n",
        "      attention_patten = cache[\"pattern\", layer]\n",
        "    S1 = attention_patten.mean(0)[h_index][-1][2].item()\n",
        "    IO = attention_patten.mean(0)[h_index][-1][4].item()\n",
        "    S2 = attention_patten.mean(0)[h_index][-1][10].item()\n",
        "\n",
        "    return IO - S1\n",
        "\n",
        "def get_head_last_token(cache, head):\n",
        "  layer, h_index = head\n",
        "  return cache[\"pattern\", layer][:, h_index, -1, :]\n",
        "\n",
        "\n",
        "def get_head_attn(cache, head, token, scores = True, mean = True):\n",
        "\n",
        "  layer, h_index = head\n",
        "\n",
        "  if scores:\n",
        "    attention_patten = cache[\"attn_scores\", layer]\n",
        "  else:\n",
        "    attention_patten = cache[\"pattern\", layer]\n",
        "\n",
        "\n",
        "  if mean:\n",
        "    if token == \"S1\":\n",
        "      return attention_patten.mean(0)[h_index][-1][2].item()\n",
        "    elif token == \"IO\":\n",
        "      return attention_patten.mean(0)[h_index][-1][4].item()\n",
        "    elif token == \"S2\":\n",
        "      return attention_patten.mean(0)[h_index][-1][10].item()\n",
        "    elif token == \"BOS\":\n",
        "      return attention_patten.mean(0)[h_index][-1][0].item()\n",
        "    else:\n",
        "      print(\"RAHHHHH YOU MISSTYPED SOMETHING\")\n",
        "\n",
        "  else:\n",
        "    if token == \"S1\":\n",
        "      return attention_patten[:, h_index, -1, 2]\n",
        "    elif token == \"IO\":\n",
        "      return attention_patten[:, h_index, -1, 4]\n",
        "    elif token == \"S2\":\n",
        "      return attention_patten[:, h_index, -1, 10]\n",
        "    elif token == \"BOS\":\n",
        "      return attention_patten[:, h_index, -1, 0]\n",
        "    else:\n",
        "      print(\"RAHHHHH YOU MISSTYPED SOMETHING\")\n",
        "\n",
        "\n",
        "def patch_head_vector(\n",
        "    head_vector: Float[Tensor, \"batch pos head_index d_head\"],\n",
        "    hook: HookPoint,\n",
        "    head_indices: int,\n",
        "    other_cache: ActivationCache\n",
        ") -> Float[Tensor, \"batch pos head_index d_head\"]:\n",
        "    '''\n",
        "    Patches the output of a given head (before it's added to the residual stream) at\n",
        "    every sequence position, using the value from the other cache.\n",
        "    '''\n",
        "    for head_index in head_indices:\n",
        "      head_vector[:, :, head_index] = other_cache[hook.name][:, :, head_index]\n",
        "    return head_vector\n",
        "\n",
        "def get_attn_results_into_head_dirs(heads, direction, scale_amounts, ablate_heads = [], freeze_ln = False, only_S1 = False):\n",
        "  io_attn_postln_nmh_results = []\n",
        "  for i in range(len(heads)):\n",
        "    io_attn_postln_nmh_results.append(causal_write_into_component(\"q\", heads[i], direction, scale_amounts,\n",
        "                                                        pre_ln = True, freeze_layernorm = freeze_ln, result_cache_function = partial(get_head_attn, token = \"IO\"), result_cache_fun_has_head_input = True, ablate_heads=ablate_heads))\n",
        "\n",
        "\n",
        "  s1_attn_postln_nmh_results = []\n",
        "  for i in range(len(heads)):\n",
        "    s1_attn_postln_nmh_results.append(causal_write_into_component(\"q\", heads[i], direction, scale_amounts,\n",
        "                                                        pre_ln = True, freeze_layernorm = freeze_ln,result_cache_function = partial(get_head_attn, token = \"S1\"), result_cache_fun_has_head_input = True, ablate_heads=ablate_heads))\n",
        "\n",
        "  s2_attn_postln_nmh_results = []\n",
        "  for i in range(len(heads)):\n",
        "    s2_attn_postln_nmh_results.append(causal_write_into_component(\"q\", heads[i], direction, scale_amounts,\n",
        "                                                        pre_ln = True, freeze_layernorm = freeze_ln,result_cache_function = partial(get_head_attn, token = \"S2\"), result_cache_fun_has_head_input = True, ablate_heads=ablate_heads))\n",
        "\n",
        "  diff_results = []\n",
        "  if not only_S1:\n",
        "    for i in range(len(heads)):\n",
        "      diff_results.append(causal_write_into_component(\"q\", heads[i], direction, scale_amounts,\n",
        "                                                          pre_ln = True, freeze_layernorm = freeze_ln,result_cache_function = get_head_IO_minus_S_attn, result_cache_fun_has_head_input = True, ablate_heads=ablate_heads))\n",
        "  else:\n",
        "    for i in range(len(heads)):\n",
        "      diff_results.append(causal_write_into_component(\"q\", heads[i], direction, scale_amounts,\n",
        "                                                          pre_ln = True, freeze_layernorm = freeze_ln,result_cache_function = get_head_IO_minus_just_S1_attn, result_cache_fun_has_head_input = True, ablate_heads=ablate_heads))\n",
        "\n",
        "\n",
        "  bos_attn_postln_nmh_results = []\n",
        "  for i in range(len(heads)):\n",
        "    bos_attn_postln_nmh_results.append(causal_write_into_component(\"q\", heads[i], direction, scale_amounts,\n",
        "                                                        pre_ln = True, freeze_layernorm = freeze_ln,result_cache_function = partial(get_head_attn, token = \"BOS\"), result_cache_fun_has_head_input = True, ablate_heads=ablate_heads))\n",
        "\n",
        "  return [io_attn_postln_nmh_results, s1_attn_postln_nmh_results, s2_attn_postln_nmh_results, diff_results, bos_attn_postln_nmh_results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA7cCUtL9-nk"
      },
      "outputs": [],
      "source": [
        "IO_unembed_direction = model.W_U.T[clean_tokens][:, 4, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHEYEw3Db6SA"
      },
      "source": [
        "# Unembedding to Not Ratios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCOgQZwub6SA"
      },
      "outputs": [],
      "source": [
        "model.set_use_attn_result(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NV33ozvEb6SB"
      },
      "outputs": [],
      "source": [
        "def get_projection(from_vector, to_vector):\n",
        "    dot_product = einops.einsum(from_vector, to_vector, \"batch d_model, batch d_model -> batch\")\n",
        "    #print(\"Average Dot Product of Output Across Batch: \" + str(dot_product.mean(0)))\n",
        "    length_of_from_vector = einops.einsum(from_vector, from_vector, \"batch d_model, batch d_model -> batch\")\n",
        "    length_of_vector = einops.einsum(to_vector, to_vector, \"batch d_model, batch d_model -> batch\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    projected_lengths = (dot_product) / (length_of_vector)\n",
        "    #print( einops.repeat(projected_lengths, \"batch -> batch d_model\", d_model = model.cfg.d_model)[0])\n",
        "    projections = to_vector * einops.repeat(projected_lengths, \"batch -> batch d_model\", d_model = to_vector.shape[-1])\n",
        "    return projections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3z7i3SAb6SB"
      },
      "outputs": [],
      "source": [
        "a = torch.Tensor([[-1, 1]])\n",
        "b = torch.Tensor([[1, 1]])\n",
        "print(get_projection(a, b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uFa7fE2b6SB"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_cosine_similarity(tensor1, tensor2):\n",
        "    # Compute cosine similarity\n",
        "    similarity = F.cosine_similarity(tensor1, tensor2, dim=1)\n",
        "    return similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSVmeqi9b6SB"
      },
      "outputs": [],
      "source": [
        "def project_vector_operation(\n",
        "    original_resid_stream: Float[Tensor, \"batch seq head_idx d_model\"],\n",
        "    hook: HookPoint,\n",
        "    vector: Float[Tensor, \"batch d_model\"],\n",
        "    position = -1,\n",
        "    heads = [], # array of ints\n",
        "    scale_proj = 1,\n",
        "    project_only = False\n",
        ") -> Float[Tensor, \"batch n_head pos pos\"]:\n",
        "  '''\n",
        "  Function which gets orthogonal projection of residual stream to a vector, and either subtracts it or keeps only it\n",
        "  '''\n",
        "  for head in heads:\n",
        "    projections = get_projection(original_resid_stream[:, position, head, :], vector)\n",
        "    if project_only:\n",
        "      original_resid_stream[:, position, head, :] = projections * scale_proj\n",
        "    else:\n",
        "      original_resid_stream[:, position, head, :] = (original_resid_stream[:, position, head, :] - projections) * scale_proj #torch.zeros(original_resid_stream[:, position, head, :].shape)#\n",
        "\n",
        "  return original_resid_stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH-_HQ5Hb6SB"
      },
      "outputs": [],
      "source": [
        "# get ldds when intervening and replacing with directions of corrupted runs\n",
        "def project_away_component_and_replace_with_something_else(\n",
        "    original_resid_out: Float[Tensor, \"batch seq head_idx d_model\"],\n",
        "    hook: HookPoint,\n",
        "    project_away_vector: Float[Tensor, \"batch d_model\"],\n",
        "    replace_vector : Float[Tensor, \"batch d_model\"],\n",
        "    position = -1,\n",
        "    heads = [], # array of ints,\n",
        "    project_only = False # whether to, instead of projecting away the vector, keep it!\n",
        ") -> Float[Tensor, \"batch n_head pos pos\"]:\n",
        "    '''\n",
        "    Function which gets removes a specific component (or keeps only it, if project_only = True) of the an output of a head and replaces it with another vector\n",
        "    '''\n",
        "    # right now this projects away the IO direction!\n",
        "    assert project_away_vector.shape == replace_vector.shape and len(project_away_vector.shape) == 2\n",
        "\n",
        "    for head in heads:\n",
        "\n",
        "        head_output = original_resid_out[:, position, head, :]\n",
        "        projections = get_projection(head_output, project_away_vector)\n",
        "\n",
        "        if project_only:\n",
        "            resid_without_projection =  projections\n",
        "        else:\n",
        "            resid_without_projection = (head_output - projections)\n",
        "\n",
        "        updated_resid = resid_without_projection + replace_vector\n",
        "        original_resid_out[:, position, head, :] = updated_resid\n",
        "\n",
        "    return original_resid_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwsRVEmQb6SB"
      },
      "outputs": [],
      "source": [
        "def patch_last_ln(ln_scale, hook):\n",
        "  #print(torch.equal(ln_scale, clean_cache[\"blocks.\" + str(hook.layer()) + \".ln1.hook_scale\"]))\n",
        "  print(\"froze lnfinal\")\n",
        "  ln_scale = clean_cache[\"ln_final.hook_scale\"]\n",
        "  return ln_scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WvoFsN1b6SB"
      },
      "outputs": [],
      "source": [
        "unembed_io_directions = model.tokens_to_residual_directions(answer_tokens[:, 0])\n",
        "unembed_s_directions = model.tokens_to_residual_directions(answer_tokens[:, 1])\n",
        "unembed_diff_directions = unembed_io_directions - unembed_s_directions\n",
        "\n",
        "target_intervene_direction = unembed_io_directions\n",
        "ln_on = True\n",
        "ca, cb, cc = calc_all_logit_diffs(clean_cache)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9IjU68Cb6SB"
      },
      "outputs": [],
      "source": [
        "def project_stuff_on_heads(project_heads, project_only = False, scale_proj = 1, output = \"display_logits\", freeze_ln = False, return_just_lds = False):\n",
        "    model.reset_hooks()\n",
        "\n",
        "    # project_heads is a list of tuples (layer, head). for each layer, write a hook which projects all the heads from the layer\n",
        "    for layer in range(model.cfg.n_layers):\n",
        "        key_heads = [head[1] for head in project_heads if head[0] == layer]\n",
        "        if len(key_heads) > 0:\n",
        "            #print(key_heads)\n",
        "            model.add_hook(utils.get_act_name(\"result\", layer), partial(project_vector_operation, vector = target_intervene_direction, heads = key_heads, scale_proj = scale_proj, project_only = project_only))\n",
        "\n",
        "    if freeze_ln:\n",
        "        for layer in [9,10,11]:\n",
        "            model.add_hook(\"blocks.\" + str(layer) + \".ln1.hook_scale\", patch_ln_scale)\n",
        "            model.add_hook(\"blocks.\" + str(layer) + \".ln2.hook_scale\", patch_ln2_scale)\n",
        "        model.add_hook(\"ln_final.hook_scale\", patch_last_ln)\n",
        "\n",
        "    hooked_logits, hooked_cache = model.run_with_cache(clean_tokens)\n",
        "    model.reset_hooks()\n",
        "    if output == \"display_logits\":\n",
        "        return display_all_logits(hooked_cache, comparison=True, logits = hooked_logits, title = f\"Projecting {('only' if project_only else 'away')} IO direction in heads {project_heads}\")\n",
        "    elif output == \"get_ldd\":\n",
        "        a,_,_ = calc_all_logit_diffs(hooked_cache)\n",
        "\n",
        "        if return_just_lds:\n",
        "          return a\n",
        "        else:\n",
        "          return a - ca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsuD-ffKb6SC"
      },
      "outputs": [],
      "source": [
        "def compare_intervention_ldds_with_sample_ablated(all_ldds, ldds_names, heads = key_backup_heads, just_logits = False):\n",
        "    results = torch.zeros((len(all_ldds), len(heads)))\n",
        "\n",
        "\n",
        "    if just_logits:\n",
        "        for ldd_index, compare_ldds in enumerate(all_ldds):\n",
        "            for i, head in enumerate(heads):\n",
        "                #print(head)\n",
        "                results[ldd_index, i] = ((compare_ldds[head[0], head[1]]).item()) # / noise_sample_ablating_results[head[0], head[1]]).item())\n",
        "    else:\n",
        "        for ldd_index, compare_ldds in enumerate(all_ldds):\n",
        "            for i, head in enumerate(heads):\n",
        "                #print(head)\n",
        "                results[ldd_index, i] = ((compare_ldds[head[0], head[1]] / noise_sample_ablating_results[head[0], head[1]]).item())\n",
        "\n",
        "    return imshow(\n",
        "        results,\n",
        "        #facet_col = 0,\n",
        "        #labels = [f\"Head {head}\" for head in key_backup_heads],\n",
        "        title=f\"The {'Ratio of Backup (Logit Diff Diff)' if not just_logits else 'Logit Diff Diffs'} of Intervention\" + (\"to Sample Ablation Backup\" if not just_logits else \"\"),\n",
        "        labels={\"x\": \"Receiver Head\", \"y\": \"Intervention\", \"color\": \"Ratio of Logit Diff Diff to Sample Ablation\" if not just_logits else \"Logit Diff Diff\"},\n",
        "        #coloraxis=dict(colorbar_ticksuffix = \"%\"),\n",
        "        # range of y-axis color from 0 to 2\n",
        "        #color_continuous_scale=\"mint\",\n",
        "        color_continuous_midpoint=1 if not just_logits else 0,\n",
        "        # give x-axis labels\n",
        "        x = [str(head) for head in heads],\n",
        "        y = ldds_names,\n",
        "        border=True,\n",
        "        width=900,\n",
        "        height = 600,\n",
        "        margin={\"r\": 100, \"l\": 100},\n",
        "        # show the values of the results above the heatmap\n",
        "        text_auto = True,\n",
        "        return_fig = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI5Q2QHob6SC"
      },
      "source": [
        "get results from replacing all IO directions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS84QDpTb6SC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def run_interventions(return_just_lds = False):\n",
        "    target_heads = [(9,6), (9,9)]#, (10,0)]\n",
        "\n",
        "\n",
        "    zero_ablate_all_heads_ldds = project_stuff_on_heads(target_heads, project_only = True, scale_proj = 0, output = \"get_ldd\", freeze_ln=ln_on, return_just_lds = return_just_lds)\n",
        "    project_only_io_direction = project_stuff_on_heads(target_heads, project_only = True, scale_proj = 1, output = \"get_ldd\", freeze_ln=ln_on, return_just_lds = return_just_lds)\n",
        "    project_away_io_direction = project_stuff_on_heads(target_heads, project_only = False, scale_proj = 1, output = \"get_ldd\", freeze_ln=ln_on, return_just_lds = return_just_lds)\n",
        "\n",
        "\n",
        "    model.reset_hooks()\n",
        "\n",
        "    if ln_on:\n",
        "        for layer in [9,10,11]:\n",
        "            model.add_hook(\"blocks.\" + str(layer) + \".ln1.hook_scale\", patch_ln_scale)\n",
        "            model.add_hook(\"blocks.\" + str(layer) + \".ln2.hook_scale\", patch_ln2_scale)\n",
        "        model.add_hook(\"ln_final.hook_scale\", patch_last_ln)\n",
        "\n",
        "    for head in target_heads:\n",
        "\n",
        "        # get the output of head on CORRUPTED RUN\n",
        "        W_O_temp = model.W_O[head[0], head[1]]\n",
        "        layer_z = corrupted_cache[utils.get_act_name(\"z\", head[0])]\n",
        "        layer_result = einops.einsum(W_O_temp, layer_z, \"d_head d_model, batch seq h_idx d_head -> batch seq h_idx d_model\")\n",
        "        output_head = layer_result[:, -1, head[1], :]\n",
        "\n",
        "        # get projection of CORRUPTED HEAD OUTPUT onto IO token\n",
        "        corrupted_head_only_IO_output = get_projection(output_head, target_intervene_direction)\n",
        "\n",
        "        # add hook to now replace with this corrupted IO direction\n",
        "        model.add_hook(utils.get_act_name(\"result\", head[0]), partial(project_away_component_and_replace_with_something_else, project_away_vector = target_intervene_direction, heads = [head[1]], replace_vector = corrupted_head_only_IO_output))\n",
        "\n",
        "    replace_with_new_IO_logits, replace_with_new_IO_cache = model.run_with_cache(clean_tokens)\n",
        "\n",
        "    model.reset_hooks()\n",
        "\n",
        "    model.reset_hooks()\n",
        "    if ln_on:\n",
        "        for layer in [9,10,11]:\n",
        "                    model.add_hook(\"blocks.\" + str(layer) + \".ln1.hook_scale\", patch_ln_scale)\n",
        "                    model.add_hook(\"blocks.\" + str(layer) + \".ln2.hook_scale\", patch_ln2_scale)\n",
        "\n",
        "    model.add_hook(\"ln_final.hook_scale\", patch_last_ln)\n",
        "    for head in target_heads:\n",
        "\n",
        "        # get the output of head on CORRUPTED RUN\n",
        "        W_O_temp = model.W_O[head[0], head[1]]\n",
        "        layer_z = corrupted_cache[utils.get_act_name(\"z\", head[0])]\n",
        "        layer_result = einops.einsum(W_O_temp, layer_z, \"d_head d_model, batch seq h_idx d_head -> batch seq h_idx d_model\")\n",
        "        output_head = layer_result[:, -1, head[1], :]\n",
        "\n",
        "\n",
        "        # get projection of CORRUPTED HEAD OUTPUT onto IO perp token\n",
        "        corrupted_head_only_IO_output = get_projection(output_head, target_intervene_direction)\n",
        "        everything_else_but_that = output_head - corrupted_head_only_IO_output\n",
        "\n",
        "        # add hook to now replace with this corrupted IO perp direction\n",
        "        model.add_hook(utils.get_act_name(\"result\", head[0]), partial(project_away_component_and_replace_with_something_else, project_away_vector = target_intervene_direction, heads = [head[1]], replace_vector = everything_else_but_that, project_only = True))\n",
        "\n",
        "    replace_with_new_perp_IO_logits, replace_with_new_perp_IO_cache = model.run_with_cache(clean_tokens)\n",
        "\n",
        "\n",
        "\n",
        "    model.reset_hooks()\n",
        "\n",
        "    if return_just_lds:\n",
        "      replace_all_IOs_ldds = calc_all_logit_diffs(replace_with_new_IO_cache)[0] - ca\n",
        "      replace_all_perp_IOs_ldds = calc_all_logit_diffs(replace_with_new_perp_IO_cache)[0] - ca\n",
        "      return [zero_ablate_all_heads_ldds, project_only_io_direction, replace_all_perp_IOs_ldds, project_away_io_direction, replace_all_IOs_ldds]\n",
        "    else:\n",
        "\n",
        "      replace_all_IOs_ldds = calc_all_logit_diffs(replace_with_new_IO_cache)[0]\n",
        "      replace_all_perp_IOs_ldds = calc_all_logit_diffs(replace_with_new_perp_IO_cache)[0]\n",
        "      return [zero_ablate_all_heads_ldds, project_only_io_direction, replace_all_perp_IOs_ldds, project_away_io_direction, replace_all_IOs_ldds]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eM_TbxZb6SC"
      },
      "outputs": [],
      "source": [
        "third_intervention = run_interventions(return_just_lds = True)\n",
        "zero_ablate_all_heads_lds, project_only_io_direction_lds, replace_all_perp_IOs_lds, project_away_io_direction, replace_all_IOs_lds = third_intervention\n",
        "\n",
        "#per_head_logit_diff, ablated_logit_diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6Xg33M0qpUs"
      },
      "outputs": [],
      "source": [
        "import plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzLfzwpOptYY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jC6TiS6Ne0j6"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter()\n",
        "x =  per_head_logit_diff.flatten()\n",
        "\n",
        "# left\n",
        "y =  replace_all_perp_IOs_lds.flatten()\n",
        "fig.add_trace(go.Scatter(x = x.cpu(), y = y.cpu(), text = fig_names, textposition=\"top center\", mode = 'markers+text', name = \"Replace IO-Perp Directions\"))\n",
        "x_range = np.linspace(start=min(fig.data[1].x) - 0.5, stop=max(fig.data[1].x) + 0.5, num=100)\n",
        "# right\n",
        "\n",
        "y =  replace_all_IOs_lds.flatten()\n",
        "fig.add_trace(go.Scatter(x = x.cpu(), y = y.cpu(), text = fig_names, textposition=\"top center\", mode = 'markers+text', name = \"Replace IO Directions\"))\n",
        "\n",
        "\n",
        "# on both\n",
        "fig.add_trace(go.Scatter(x=x_range, y=x_range, mode='lines', name='y=x', line_color = \"black\", ))\n",
        "  #y =  ablated_logit_diff.flatten()\n",
        "  #fig.add_trace(go.Scatter(x = x.cpu(), y = y.cpu(),  textposition=\"top center\", mode = 'markers+text', name = \"sample ablated\", marker=dict(color=\"purple\")), row = 1, col = col)\n",
        "\n",
        "\n",
        "\n",
        "fig.update_xaxes(title = \"Clean Direct Effect\")\n",
        "fig.update_yaxes(title = \"Ablated Direct Effect\")\n",
        "fig.update_layout(title = \"Logit Differences When Zero Ablating in Name Mover Heads\", width = 950)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbmwz3AEe0j6"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = px.scatter()\n",
        "x =  per_head_logit_diff.flatten()\n",
        "\n",
        "# left\n",
        "y =  project_only_io_direction_lds.flatten()\n",
        "fig.add_trace(go.Scatter(x = x.cpu(), y = y.cpu(), text = fig_names, textposition=\"top center\", mode = 'markers+text', name = \"Only include IO\"))\n",
        "x_range = np.linspace(start=min(fig.data[1].x) - 0.5, stop=max(fig.data[1].x) + 0.5, num=100)\n",
        "# right\n",
        "\n",
        "y =  project_away_io_direction.flatten()\n",
        "fig.add_trace(go.Scatter(x = x.cpu(), y = y.cpu(), text = fig_names, textposition=\"top center\", mode = 'markers+text', name = \"Only include IO-perp\"))\n",
        "\n",
        "\n",
        "# on both\n",
        "fig.add_trace(go.Scatter(x=x_range, y=x_range, mode='lines', name='y=x', line_color = \"black\", ))\n",
        "  #y =  ablated_logit_diff.flatten()\n",
        "  #fig.add_trace(go.Scatter(x = x.cpu(), y = y.cpu(),  textposition=\"top center\", mode = 'markers+text', name = \"sample ablated\", marker=dict(color=\"purple\")), row = 1, col = col)\n",
        "\n",
        "\n",
        "\n",
        "fig.update_xaxes(title = \"Clean Direct Effect\")\n",
        "fig.update_yaxes(title = \"Ablated Direct Effect\")\n",
        "fig.update_layout(title = \"Logit Differences When Zero Ablating in Name Mover Heads\", width = 950)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bmR7Fr4b6SD"
      },
      "outputs": [],
      "source": [
        "# average across all three interventions\n",
        "all_interventions = [third_intervention]#, second_intervention, new_intervention]\n",
        "average_interventions = []\n",
        "for i in range(len(third_intervention)):\n",
        "    average_interventions.append((third_intervention[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGAKNMw_b6SD"
      },
      "source": [
        "get results from replacing all perp to IO directions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TO6STSw3b6SD"
      },
      "outputs": [],
      "source": [
        "fig = compare_intervention_ldds_with_sample_ablated([ca - ca] + average_interventions  + [noise_sample_ablating_results],\n",
        "                                               [\"Clean Run\", \"Zero Ablation of NMHs\", \"Project Only IO Direction (Zero ⊥ IO direction)\", \"Replace ⊥ IO directions with Corrupted ⊥ IO directions\", \"Project Away IO Direction (Zero IO direction)\", \"Replace IO directions with Corrupted IO directions\",  \"Sample Ablation of NMHs\"],\n",
        "                                               heads = key_backup_heads + neg_m_heads, just_logits = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGAQqibtb6SD"
      },
      "outputs": [],
      "source": [
        "# draw a rectangle in the fig\n",
        "fig.add_shape(\n",
        "    # unfilled Rectangle\n",
        "        type=\"rect\",\n",
        "        x0=-0.5,\n",
        "        y0=-0.5,\n",
        "        x1=3.5,\n",
        "        y1=6.49,\n",
        "        line=dict(\n",
        "            color=\"Black\",\n",
        "            #linewidth = 3\n",
        "        ),\n",
        "        #fillcolor=\"RoyalBlue\",\n",
        "        opacity=1,\n",
        "        layer=\"above\",\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "fig.add_shape(\n",
        "    # unfilled Rectangle\n",
        "        type=\"rect\",\n",
        "        x0=3.5,\n",
        "        y0=-0.5,\n",
        "        x1=5.5,\n",
        "        y1=6.49,\n",
        "        line=dict(\n",
        "            color=\"Black\",\n",
        "            #linewidth = 3\n",
        "        ),\n",
        "        #fillcolor=\"RoyalBlue\",\n",
        "        opacity=1,\n",
        "        layer=\"above\",\n",
        "\n",
        "    )\n",
        "\n",
        "# add text above the rectangle but on plot (not in cells)\n",
        "# fig.add_annotation(\n",
        "\n",
        "#         x=0,\n",
        "#         y=0,\n",
        "#         text=\"Interventions\",\n",
        "#         showarrow=False,\n",
        "#         yshift=10,\n",
        "# )\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5VrmQxKb6SD"
      },
      "outputs": [],
      "source": [
        "# for index, i in enumerate([zero_ablate_all_heads_ldds, project_only_io_direction, replace_all_perp_IOs_ldds,  project_away_io_direction, replace_all_IOs_ldds, noise_sample_ablating_results]):\n",
        "#     imshow(i,\n",
        "#            title = [\"Zero Ablation of NMHs\", \"Project Only IO Direction (Zero ⊥ IO direction)\", \"Replace ⊥ IO directions with Corrupted ⊥ IO directions\", \"Project Away IO Direction (Zero IO direction)\", \"Replace IO directions with Corrupted IO directions\",  \"Sample Ablation of NMHs\"][index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnwgen14b6SD"
      },
      "outputs": [],
      "source": [
        "# find cosine similarity of 9.0 output and IO unembedding\n",
        "for head in neg_m_heads:\n",
        "    print(\"Mean Cossim similarity between IO unembedding and \" + str(head) + \":\")\n",
        "    W_O_temp = model.W_O[head[0], head[1]]\n",
        "    layer_z = clean_cache[utils.get_act_name(\"z\", head[0])]\n",
        "    layer_result = einops.einsum(W_O_temp, layer_z, \"d_head d_model, batch seq h_idx d_head -> batch seq h_idx d_model\")\n",
        "    output_head = layer_result[:, -1, head[1], :]\n",
        "\n",
        "    # get projection of CORRUPTED HEAD OUTPUT onto IO token\n",
        "    corrupted_head_only_IO_output = compute_cosine_similarity(output_head, target_intervene_direction)\n",
        "    print(corrupted_head_only_IO_output.mean(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBQhmarib6SE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6sNBhJFe0j7"
      },
      "source": [
        "### How much does Copy Suppression explain Self-Repair in the Negative Heads?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZ_MijCwe0j8"
      },
      "outputs": [],
      "source": [
        "cache_patching_NMHs = act_patch(\n",
        "    model = model,\n",
        "    orig_input = clean_tokens,\n",
        "    new_cache = corrupted_cache,\n",
        "    patching_nodes = [Node(\"z\", layer = 9 , head = 6) , Node(\"z\", layer = 9 , head = 9), Node(\"z\", layer = 10 , head = 0)],\n",
        "    patching_metric = return_item,\n",
        "    verbose = False,\n",
        "    apply_metric_to_cache = True\n",
        ")\n",
        "\n",
        "patched_NMHs_logit_diff ,_,_ = calc_all_logit_diffs(cache_patching_NMHs)\n",
        "\n",
        "\n",
        "# sum over last two layers of backup, but not including 10.0\n",
        "patched_NMHS_backup = patched_NMHs_logit_diff - per_head_logit_diff\n",
        "assert patched_NMHS_backup[:9].flatten().sum() == 0\n",
        "actual_backup_CRS = patched_NMHS_backup.flatten().sum() - patched_NMHS_backup[10, 0] - patched_NMHS_backup[9,9] - patched_NMHS_backup[9,6]\n",
        "self_repair_in_negative_heads = patched_NMHS_backup[10, 7] + patched_NMHS_backup[11,10]\n",
        "print(\"Perent self repair explained by negative heads: \", self_repair_in_negative_heads / actual_backup_CRS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5-49pYCe0j8"
      },
      "outputs": [],
      "source": [
        "model.set_use_attn_result(True)\n",
        "# sum over last two layers of backup\n",
        "all_NMH_project_no_io = project_stuff_on_heads(name_mover_heads, project_only = False, scale_proj = 1, output = \"get_ldd\", freeze_ln=True, return_just_lds = True)\n",
        "project_stuff_on_heads(name_mover_heads, project_only = False, scale_proj = 1, output = \"display_logits\", freeze_ln=True, return_just_lds = True)\n",
        "model.set_use_attn_result(False)\n",
        "\n",
        "\n",
        "just_projection_self_repair = all_NMH_project_no_io - per_head_logit_diff\n",
        "assert just_projection_self_repair[:9].flatten().sum().abs() <= 0.001\n",
        "just_projection_CRS = just_projection_self_repair.flatten().sum() - just_projection_self_repair[10, 0] - just_projection_self_repair[9,6] - just_projection_self_repair[9,9]\n",
        "just_projection_negative_head_self_repair = just_projection_self_repair[10, 7] + just_projection_self_repair[11,10]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2qC3Vs6e0j9"
      },
      "outputs": [],
      "source": [
        "print(f\"Negative Heads make this much of Self-Repair: {self_repair_in_negative_heads / actual_backup_CRS}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffu9ks6Be0j9"
      },
      "outputs": [],
      "source": [
        "print(f\"Copy Suppression explains how much in Negative Heads: {just_projection_negative_head_self_repair / self_repair_in_negative_heads}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvEUUTyIe0j9"
      },
      "outputs": [],
      "source": [
        "just_projection_negative_head_self_repair / actual_backup_CRS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiQGrqKke0j9"
      },
      "source": [
        "# Static experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNLCYyA3e0j-"
      },
      "outputs": [],
      "source": [
        "!git fetch https://github.com/callummcdougall/SERI-MATS-2023-Streamlit-pages/blob/d2a6ca671b9023abcdfb024c216418119b327e2e/transformer_lens/rs/callum2/explore_prompts/model_results_3.py#L275C1-L275C1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl0P21Eme0j-"
      },
      "outputs": [],
      "source": [
        "def get_effective_embedding(model: HookedTransformer) -> Float[Tensor, \"d_vocab d_model\"]:\n",
        "\n",
        "    # TODO - make this consistent (i.e. change the func in `generate_bag_of_words_quad_plot` to also return W_U and W_E separately)\n",
        "\n",
        "    W_E = model.W_E.clone()\n",
        "    W_U = model.W_U.clone()\n",
        "    # t.testing.assert_close(W_E[:10, :10], W_U[:10, :10].T)  NOT TRUE, because of the center unembed part!\n",
        "\n",
        "    resid_pre = W_E.unsqueeze(0)\n",
        "    pre_attention = model.blocks[0].ln1(resid_pre)\n",
        "    attn_out = einops.einsum(\n",
        "        pre_attention,\n",
        "        model.W_V[0],\n",
        "        model.W_O[0],\n",
        "        \"b s d_model, num_heads d_model d_head, num_heads d_head d_model_out -> b s d_model_out\",\n",
        "    )\n",
        "    resid_mid = attn_out + resid_pre\n",
        "    normalized_resid_mid = model.blocks[0].ln2(resid_mid)\n",
        "    mlp_out = model.blocks[0].mlp(normalized_resid_mid)\n",
        "\n",
        "    W_EE = mlp_out.squeeze()\n",
        "    W_EE_full = resid_mid.squeeze() + mlp_out.squeeze()\n",
        "\n",
        "    W_ONLY_MLP = resid_pre.squeeze() + model.blocks[0].mlp(model.blocks[0].ln2(resid_pre)).squeeze()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return {\n",
        "        \"W_E (no MLPs)\": W_E,\n",
        "        \"W_U\": W_U.T,\n",
        "        # \"W_E (raw, no MLPs)\": W_E,\n",
        "        \"W_E (including MLPs)\": W_EE_full,\n",
        "        \"W_E (only MLPs)\": W_EE,\n",
        "        \"Cody MLP\": W_ONLY_MLP,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GB40ziWe0j-"
      },
      "outputs": [],
      "source": [
        "embeddings = get_effective_embedding(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXLRZCnme0j-"
      },
      "outputs": [],
      "source": [
        "def combined_1_acc_iteration(full_OV_circuit: FactoredMatrix, top = True):\n",
        "  actual_matrix = full_OV_circuit.AB\n",
        "  top_sum = 0\n",
        "  min_sum = 0\n",
        "\n",
        "  #print(actual_matrix.shape[0])\n",
        "  for col in range(actual_matrix.shape[0]):\n",
        "\n",
        "    column = actual_matrix[:, col]\n",
        "    top_sum += 1 if (column.argmax() == col).item() else 0\n",
        "    min_sum += 1 if (column.argmin() == col).item() else 0\n",
        "  return (top_sum - min_sum) / actual_matrix.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "names_list =  saved_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XEK1sTLe0j-"
      },
      "outputs": [],
      "source": [
        "def lock_attn(\n",
        "    attn_patterns: Float[torch.Tensor, \"batch head_idx dest_pos src_pos\"],\n",
        "    hook: HookPoint,\n",
        ") -> Float[torch.Tensor, \"batch head_idx dest_pos src_pos\"]:\n",
        "    print(\"LOCKING\")\n",
        "    assert isinstance(attn_patterns, Float[torch.Tensor, \"batch head_idx dest_pos src_pos\"]) # ensure shape is correct\n",
        "    assert hook.layer() == 0 # only do this on layer 0\n",
        "    batch, n_heads, seq_len = attn_patterns.shape[:3]\n",
        "\n",
        "    attn_new = einops.repeat(torch.eye(seq_len), \"dest src -> batch head_idx dest src\", batch=batch, head_idx=n_heads).clone().to(attn_patterns.device)\n",
        "    return attn_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_X41HWse0j-",
        "outputId": "d44d69db-3a45-46bb-c3b8-d403d0301688"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50257, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "embeddings[\"Cody MLP\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ0-MfDwe0j-",
        "outputId": "7be06079-34f9-49be-e11e-62ea14a8974e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([141, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "model.to_tokens(names, prepend_bos=False).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoSyJk2Qe0j-"
      },
      "outputs": [],
      "source": [
        "def look_at_backup_circuit(\n",
        "    model: HookedTransformer,\n",
        "    head_one: Tuple[int, int],\n",
        "    head_two: Tuple[int, int],\n",
        "    names,\n",
        "    show_matrix = True,\n",
        "    negative = False,\n",
        "    both = False # use a combined metric which does both positive and negative backup at once\n",
        "):\n",
        "    \"\"\"\n",
        "    Shows the strength of the backup - W_OV^A, W_QK^B circuit - between heads\n",
        "    or, the negative backup if negative = True\n",
        "    \"\"\"\n",
        "\n",
        "    # Define components from our model (for typechecking, and cleaner code)\n",
        "    embed = model.embed\n",
        "    mlp0 = model.blocks[0].mlp\n",
        "    ln0 = model.blocks[0].ln2\n",
        "    unembed = model.unembed\n",
        "    ln_final = model.ln_final\n",
        "\n",
        "    # # Get embeddings for the names in our list\n",
        "    # name_tokens: Int[Tensor, \"batch 1\"] = model.to_tokens(names, prepend_bos=False)\n",
        "    # name_embeddings: Int[Tensor, \"batch 1 d_model\"] = embed(name_tokens)\n",
        "\n",
        "    # # Get residual stream after applying MLP\n",
        "    # resid_after_mlp1 = name_embeddings + mlp0(ln0(name_embeddings)) # seq 1 d_model\n",
        "    # resid_after_mlp1 = resid_after_mlp1[:, 0, :]\n",
        "\n",
        "    # Get MLP Embeddings\n",
        "    name_tokens: Int[Tensor, \"batch 1\"] = model.to_tokens(names, prepend_bos=False)\n",
        "    #print(name_tokens.shape)\n",
        "    #embed_plus_MLP = embeddings[\"W_E (including MLPs)\"]\n",
        "    embed_plus_MLP = embeddings[\"Cody MLP\"]\n",
        "    name_embeddings = embed_plus_MLP[name_tokens][:, 0, :]\n",
        "    #print(name_embeddings.shape)\n",
        "\n",
        "\n",
        "    # calculate the OV matrix of head two\n",
        "    A_O = model.W_O[head_one[0], head_one[1]]\n",
        "    A_V = model.W_V[head_one[0], head_one[1]]\n",
        "    A_OV_Circuit = FactoredMatrix(A_V, A_O)\n",
        "\n",
        "    # calculate the QK matrix of head two\n",
        "    B_Q = model.W_Q[head_two[0], head_two[1]]\n",
        "    B_K = model.W_K[head_two[0], head_two[1]]\n",
        "\n",
        "\n",
        "    if negative and not both:\n",
        "      B_QK_Circuit = FactoredMatrix(-B_Q, B_K.T)\n",
        "    else:\n",
        "      B_QK_Circuit = FactoredMatrix(B_Q, B_K.T)\n",
        "\n",
        "\n",
        "    relationship = A_OV_Circuit @ B_QK_Circuit # this is the A by B compositioin we want\n",
        "\n",
        "    # put token embeddings around this matrix\n",
        "    full_circuit = name_embeddings @ relationship @ name_embeddings.T\n",
        "\n",
        "    # we got to find a way to combine both these metrics into one\n",
        "    # fortunately, one easy way of doing this is just adding one if it is top_1, subtracting one if it is bottom_1\n",
        "    top_1 = combined_1_acc_iteration(full_circuit)\n",
        "\n",
        "\n",
        "    if show_matrix:\n",
        "      print(\"THiS HAS NOT BEEN TESTED\")\n",
        "      print(top_1)\n",
        "      print(top_5)\n",
        "      imshow (\n",
        "          full_circuit.AB,\n",
        "          labels={\"x\": \"Input token\", \"y\": \"Attention to output token\"},\n",
        "          title=\"Full Backup composition between head \" + str(head_one) +\" and \"+ str(head_two),\n",
        "          width=700,\n",
        "          x = model.to_str_tokens(name_tokens),\n",
        "          y = model.to_str_tokens(name_tokens)\n",
        "      )\n",
        "    else:\n",
        "      return top_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "734ObnB2e0j-"
      },
      "outputs": [],
      "source": [
        "def display_back_scores(B_layer, B_head, negative = False, both = False):\n",
        "  \"\"\"\n",
        "  displays all backup scores of heads with the head (B_layer, B_head)\n",
        "  \"\"\"\n",
        "\n",
        "  backup_circuitry_11_7 = torch.zeros((12, 12))\n",
        "  for layer in range(12):\n",
        "    for head in range(12):\n",
        "\n",
        "      top_1 = look_at_backup_circuit(model, (layer,head), (B_layer, B_head), names, show_matrix = False, negative = negative, both = both)\n",
        "\n",
        "\n",
        "      backup_circuitry_11_7[layer][head] = top_1\n",
        "\n",
        "  imshow (\n",
        "          backup_circuitry_11_7,\n",
        "          labels={\"x\": \"Head\", \"y\": \"Layer\"},\n",
        "          title=f\"Backup Circuit Score with {B_layer}.{B_head}\" if not negative else f\"Negative Backup Circuit Score with {B_layer}.{B_head}\",\n",
        "          width=700,\n",
        "          range_color = [-1, 1]\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "v1AHFeTUe0j-",
        "outputId": "b8888557-e2a4-46d3-a5d9-9a7e1939c520"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"90a6deee-1197-459a-9d38-dfe1a980352b\" class=\"plotly-graph-div\" style=\"height:525px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"90a6deee-1197-459a-9d38-dfe1a980352b\")) {                    Plotly.newPlot(                        \"90a6deee-1197-459a-9d38-dfe1a980352b\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[-0.014184396713972092,-0.014184396713972092,-0.014184396713972092,0.0,0.007092198356986046,0.0,-0.021276595070958138,-0.007092198356986046,0.014184396713972092,-0.014184396713972092,-0.007092198356986046,0.0],[0.021276595070958138,0.0,0.0,0.007092198356986046,0.014184396713972092,0.021276595070958138,-0.028368793427944183,0.007092198356986046,0.007092198356986046,0.0,0.014184396713972092,0.007092198356986046],[-0.028368793427944183,0.0,0.03546099364757538,0.007092198356986046,0.0,0.014184396713972092,-0.007092198356986046,0.0,-0.007092198356986046,0.014184396713972092,-0.014184396713972092,0.0],[-0.03546099364757538,-0.021276595070958138,0.0,0.0,0.05673758685588837,0.007092198356986046,0.021276595070958138,0.014184396713972092,0.007092198356986046,-0.028368793427944183,0.021276595070958138,-0.014184396713972092],[-0.021276595070958138,0.0,0.014184396713972092,0.0,0.04964539036154747,-0.014184396713972092,0.014184396713972092,-0.014184396713972092,-0.014184396713972092,-0.014184396713972092,-0.007092198356986046,0.0],[-0.028368793427944183,-0.2978723347187042,0.007092198356986046,0.007092198356986046,0.014184396713972092,-0.07092198729515076,0.0,-0.021276595070958138,0.007092198356986046,0.09219858050346375,-0.03546099364757538,0.05673758685588837],[-0.021276595070958138,-0.021276595070958138,-0.007092198356986046,0.0,0.014184396713972092,0.007092198356986046,0.06382978707551956,-0.042553190141916275,-0.014184396713972092,-0.4964539110660553,-0.014184396713972092,-0.007092198356986046],[-0.03546099364757538,-0.1631205677986145,-0.3404255211353302,0.2978723347187042,0.0,-0.04964539036154747,0.1843971610069275,-0.07092198729515076,-0.12765957415103912,0.20567375421524048,-0.07092198729515076,0.0],[-0.007092198356986046,-0.21985815465450287,0.0,0.0,-0.028368793427944183,-0.042553190141916275,-0.007092198356986046,-0.042553190141916275,-0.028368793427944183,0.08510638028383255,0.567375898361206,-0.11347517371177673],[0.1560283750295639,-0.014184396713972092,0.021276595070958138,-0.09929078072309494,0.04964539036154747,0.07801418751478195,0.41134750843048096,0.09929078072309494,0.21985815465450287,0.04964539036154747,-0.007092198356986046,-0.007092198356986046],[0.41134750843048096,0.007092198356986046,-0.007092198356986046,-0.007092198356986046,-0.021276595070958138,-0.014184396713972092,0.007092198356986046,0.1631205677986145,0.0,0.014184396713972092,0.03546099364757538,-0.07092198729515076],[0.0,0.0,0.07092198729515076,0.03546099364757538,-0.021276595070958138,-0.028368793427944183,-0.007092198356986046,-0.028368793427944183,-0.007092198356986046,-0.014184396713972092,0.03546099364757538,0.007092198356986046]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0,\"cmin\":-1,\"cmax\":1},\"title\":{\"text\":\"Negative Backup Circuit Score with 10.0\"},\"width\":700},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('90a6deee-1197-459a-9d38-dfe1a980352b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display_back_scores(10, 0, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jd_RNs4e0j_"
      },
      "outputs": [],
      "source": [
        "def gather_backup_scores_between_heads(ov_head_list, qk_head_list, negative = False, both = False):\n",
        "  \"\"\"\n",
        "  gathers backup scores between heads in a list\n",
        "  \"\"\"\n",
        "\n",
        "  scores = torch.zeros((len(ov_head_list), len(qk_head_list)))\n",
        "  for i, head_i in enumerate(ov_head_list):\n",
        "    for j, head_j in enumerate(qk_head_list):\n",
        "      top1 =  look_at_backup_circuit(model, head_i, head_j, names_list, show_matrix=False, negative = negative,both = both)\n",
        "\n",
        "      if head_i[0] < head_j[0]:\n",
        "        scores[i][j] = top1\n",
        "      else:\n",
        "        scores[i][j] = np.nan\n",
        "\n",
        "\n",
        "  return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW9fzdMve0j_"
      },
      "outputs": [],
      "source": [
        "all_heads_list =  [(10,7), (11,10)] + [(9,9), (9,6), (10,0)] + [(10,2), (10,6), (10,10), (11,2)] + [(10,7), (11,10)]\n",
        "#all_heads_list = [all_heads_list[-1 - i] for i in range(len(all_heads_list))]\n",
        "ov_heads_list = [head for head in all_heads_list if head[0] == 9] + [(9,1)]\n",
        "qk_heads_list = [head for head in all_heads_list if head[0] != 9] + [(11,0)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "interesting_head_backup_scores = gather_backup_scores_between_heads(ov_heads_list, qk_heads_list, negative = False, both = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkG2vnk1e0j_",
        "outputId": "f69afd00-0488-473d-d732-87d89f8db122"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "interesting_head_backup_scores.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "xGkCkuRJe0j_",
        "outputId": "bd701197-86e7-49e3-dc04-1f85fee333c3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"36865e39-f2fc-4fc4-87c6-60e342000f61\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"36865e39-f2fc-4fc4-87c6-60e342000f61\")) {                    Plotly.newPlot(                        \"36865e39-f2fc-4fc4-87c6-60e342000f61\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"(10, 7)\",\"(11, 10)\",\"(10, 0)\",\"(10, 2)\",\"(10, 6)\",\"(10, 10)\",\"(11, 2)\",\"(10, 7)\",\"(11, 10)\",\"(11, 0)\"],\"y\":[\"(9, 9)\",\"(9, 6)\",\"(9, 1)\"],\"z\":[[1.0,1.0,-0.04964539036154747,-0.347517728805542,-0.06382978707551956,-0.2978723347187042,-0.6453900933265686,1.0,1.0,0.07092198729515076],[0.9645389914512634,0.8794326186180115,-0.41134750843048096,-0.26950353384017944,-0.1631205677986145,-0.19858156144618988,-0.609929084777832,0.9645389914512634,0.8794326186180115,0.04964539036154747],[0.19858156144618988,0.0,0.014184396713972092,-0.06382978707551956,0.0,0.014184396713972092,0.03546099364757538,0.19858156144618988,0.0,0.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"QK Head: %{x}\\u003cbr\\u003eOV Head: %{y}\\u003cbr\\u003eSimilarity to \\u00b1 Identity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"QK Head\"},\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"OV Head\"},\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Similarity to \\u00b1 Identity\"}},\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Static Backup Identity Scores between Key Heads\"},\"width\":800,\"legend\":{\"title\":{\"font\":{\"color\":\"green\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('36865e39-f2fc-4fc4-87c6-60e342000f61');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = imshow(\n",
        "        interesting_head_backup_scores,\n",
        "        return_fig = True,\n",
        "        title=\"Static Backup Identity Scores between Key Heads\",\n",
        "        x = [str(i) for i in qk_heads_list], y = [str(i) for i in ov_heads_list],\n",
        "        labels={\"x\": \"QK Head\", \"y\": \"OV Head\", \"color\": \"Similarity to ± Identity\"},\n",
        "        #coloraxis=dict(colorbar_ticksuffix = \"%\"),\n",
        "        border=True,\n",
        "        width=800,\n",
        "        #margin={\"r\": 100, \"l\": 100},\n",
        "        color_continuous_scale = \"RdBu\",\n",
        "        #midpoint = 0,\n",
        "    )\n",
        "\n",
        "# fig.add_shape(type=\"rect\",\n",
        "#     x0=-0.5, y0=-0.5, x1=6.5, y1=1.5,\n",
        "#     fillcolor=\"white\",\n",
        "#               layer='below',\n",
        "#     line=dict(color=\"white\"),\n",
        "# )\n",
        "\n",
        "fig.update_layout(\n",
        "    #font_family=\"Courier New\",\n",
        "    #font_color=\"blue\",\n",
        "    #title_font_family=\"Times New Roman\",\n",
        "    #title_font_color=\"red\",\n",
        "    legend_title_font_color=\"green\",\n",
        "    #height =400\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkSyiMwne0j_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYPrO55ve0j_"
      },
      "source": [
        "# What percent of downstream heads have strong backup with above?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f44m1TZ0e0j_"
      },
      "outputs": [],
      "source": [
        "all_heads_list =  [(10,7), (11,10)] + [(9,9), (9,6), (10,0)] + [(10,2), (10,6), (10,10), (11,2)] + [(10,7), (11,10)]\n",
        "#all_heads_list = [all_heads_list[-1 - i] for i in range(len(all_heads_list))]\n",
        "name_mover_heads = [(9,9), (9,6), (10,0)]\n",
        "ov_heads_list = name_mover_heads#[[9,i] for i in range(12)] + [[10,i] for i in range(12)] + [[11,i] for i in range(12)]\n",
        "qk_heads_list = [[10,i] for i in range(12)] + [[11,i] for i in range(12)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "interesting_head_backup_scores = gather_backup_scores_between_heads(ov_heads_list, qk_heads_list, negative = False, both = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "zV4OsiEbe0j_",
        "outputId": "ce704b80-b83a-4973-b662-0bcbd138de7d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"de0e2b68-8aa9-4052-b3f0-6f706b739e32\" class=\"plotly-graph-div\" style=\"height:350px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"de0e2b68-8aa9-4052-b3f0-6f706b739e32\")) {                    Plotly.newPlot(                        \"de0e2b68-8aa9-4052-b3f0-6f706b739e32\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"10.0\",\"10.1\",\"10.2\",\"10.3\",\"10.4\",\"10.5\",\"10.6\",\"10.7\",\"10.8\",\"10.9\",\"10.10\",\"10.11\",\"11.0\",\"11.1\",\"11.2\",\"11.3\",\"11.4\",\"11.5\",\"11.6\",\"11.7\",\"11.8\",\"11.9\",\"11.10\",\"11.11\"],\"y\":[\"9.9\",\"9.6\",\"10.0\"],\"z\":[[-0.04964539036154747,-0.021276595070958138,-0.347517728805542,-0.028368793427944183,-0.014184396713972092,-0.014184396713972092,-0.06382978707551956,1.0,-0.014184396713972092,0.014184396713972092,-0.2978723347187042,-0.007092198356986046,0.07092198729515076,-0.07092198729515076,-0.6453900933265686,-0.05673758685588837,-0.014184396713972092,0.042553190141916275,-0.24113474786281586,0.028368793427944183,0.0,0.028368793427944183,1.0,-0.03546099364757538],[-0.41134750843048096,-0.07801418751478195,-0.26950353384017944,-0.021276595070958138,-0.007092198356986046,-0.007092198356986046,-0.1631205677986145,0.9645389914512634,0.0,0.014184396713972092,-0.19858156144618988,-0.03546099364757538,0.04964539036154747,-0.06382978707551956,-0.609929084777832,-0.09219858050346375,0.007092198356986046,0.0,-0.26950353384017944,0.0,0.0,-0.042553190141916275,0.8794326186180115,-0.04964539036154747],[null,null,null,null,null,null,null,null,null,null,null,null,0.07801418751478195,-0.12056737393140793,-0.957446813583374,-0.326241135597229,0.04964539036154747,-0.007092198356986046,-0.09219858050346375,-0.03546099364757538,0.021276595070958138,-0.05673758685588837,0.7943262457847595,-0.12056737393140793]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"QK Head: %{x}\\u003cbr\\u003eOV Head: %{y}\\u003cbr\\u003eSimilarity to \\u00b1 Identity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"QK Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"OV Head\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Similarity to \\u00b1 Identity\"}},\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Static Backup Identity Scores between Key Heads\"},\"width\":1000,\"shapes\":[{\"fillcolor\":\"white\",\"layer\":\"above\",\"line\":{\"color\":\"black\",\"width\":1},\"type\":\"rect\",\"x0\":-0.5,\"x1\":11.5,\"y0\":1.5,\"y1\":2.5},{\"fillcolor\":\"white\",\"layer\":\"above\",\"line\":{\"color\":\"black\",\"width\":1},\"type\":\"line\",\"x0\":-0.5,\"x1\":11.5,\"y0\":1.5,\"y1\":1.5},{\"fillcolor\":\"white\",\"layer\":\"above\",\"line\":{\"color\":\"black\",\"width\":1},\"type\":\"line\",\"x0\":11.5,\"x1\":11.5,\"y0\":1.5,\"y1\":2.5}],\"legend\":{\"title\":{\"font\":{\"color\":\"green\"}}},\"height\":350},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('de0e2b68-8aa9-4052-b3f0-6f706b739e32');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = imshow(\n",
        "        interesting_head_backup_scores,\n",
        "        return_fig = True,\n",
        "        title=\"Static Backup Identity Scores between Key Heads\",\n",
        "        x = [str(i[0]) + \".\" + str(i[1]) for i in qk_heads_list], y = [str(i[0]) + \".\" + str(i[1]) for i in ov_heads_list],\n",
        "        labels={\"x\": \"QK Head\", \"y\": \"OV Head\", \"color\": \"Similarity to ± Identity\"},\n",
        "        #coloraxis=dict(colorbar_ticksuffix = \"%\"),\n",
        "        border=False,\n",
        "        width=800,\n",
        "        #margin={\"r\": 100, \"l\": 100},\n",
        "        color_continuous_scale = \"RdBu\",\n",
        "        #midpoint = 0,\n",
        "    )\n",
        "\n",
        "fig.add_shape(type=\"rect\",\n",
        "    x0=-0.5, y0=1.5, x1=11.5, y1=2.5,\n",
        "    fillcolor=\"white\",\n",
        "              layer='above',\n",
        "    # no line\n",
        "    line = dict(\n",
        "        color=\"black\",\n",
        "        width=1,\n",
        "    ),\n",
        "    # have shape be on top\n",
        "    #xref='x', yref='y',\n",
        ")\n",
        "\n",
        "\n",
        "fig.add_shape(type=\"line\",\n",
        "    x0=-0.5, y0=1.5, x1=11.5, y1=1.5,\n",
        "    fillcolor=\"white\",\n",
        "              layer='above',\n",
        "    # no line\n",
        "    line = dict(\n",
        "        color=\"black\",\n",
        "        width=1,\n",
        "    ),\n",
        "    # have shape be on top\n",
        "    #xref='x', yref='y',\n",
        ")\n",
        "\n",
        "fig.add_shape(type=\"line\",\n",
        "    x0=11.5, y0=1.5, x1=11.5, y1=2.5,\n",
        "    fillcolor=\"white\",\n",
        "              layer='above',\n",
        "    # no line\n",
        "    line = dict(\n",
        "        color=\"black\",\n",
        "        width=1,\n",
        "    ),\n",
        "    # have shape be on top\n",
        "    #xref='x', yref='y',\n",
        ")\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    #font_family=\"Courier New\",\n",
        "    #font_color=\"blue\",\n",
        "    #title_font_family=\"Times New Roman\",\n",
        "    #title_font_color=\"red\",\n",
        "    legend_title_font_color=\"green\",\n",
        "    width = 1000,\n",
        "    height = 350\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S23ptpse0kA"
      },
      "outputs": [],
      "source": [
        "fig.write_image(\"sbis_scores.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m30SnjdXe0kA",
        "outputId": "d7c9c0ab-8762-47e3-b5e1-8ba88308a018"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['10.0',\n",
              " '10.1',\n",
              " '10.2',\n",
              " '10.3',\n",
              " '10.4',\n",
              " '10.5',\n",
              " '10.6',\n",
              " '10.7',\n",
              " '10.8',\n",
              " '10.9',\n",
              " '10.10',\n",
              " '10.11',\n",
              " '11.0',\n",
              " '11.1',\n",
              " '11.2',\n",
              " '11.3',\n",
              " '11.4',\n",
              " '11.5',\n",
              " '11.6',\n",
              " '11.7',\n",
              " '11.8',\n",
              " '11.9',\n",
              " '11.10',\n",
              " '11.11']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "[str(i[0]) + \".\" + str(i[1]) for i in qk_heads_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1dWvN1Te0kA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Gv5obrKX0dZD",
        "pmcwuLTTTrhY",
        "680GmxIhgu-6",
        "KtGaksXue0j1",
        "tnOqH2XMgznE",
        "iHEYEw3Db6SA"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "506a46f8c2804e4e80c097f121ebf770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ce8558086424ca1b71642ca51c8a3ef",
              "IPY_MODEL_4228c933053149ff8de0b2280e567159",
              "IPY_MODEL_7bafeb6aebb043718a3e25fc3e915684"
            ],
            "layout": "IPY_MODEL_b06ce165db014a8d85899d711a36aa28"
          }
        },
        "9ce8558086424ca1b71642ca51c8a3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_063b8e295a5945b1aa61fa81212b81ec",
            "placeholder": "​",
            "style": "IPY_MODEL_e51c208c8345426c9af3677382636cdd",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "4228c933053149ff8de0b2280e567159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a720266ceee413cb671125c84794a6b",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d4ef212d224461e8209ce14d126cff2",
            "value": 665
          }
        },
        "7bafeb6aebb043718a3e25fc3e915684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bcea851e4ac47759ad3a97406854889",
            "placeholder": "​",
            "style": "IPY_MODEL_3f8abd16404341ca83b21b717d4256ec",
            "value": " 665/665 [00:00&lt;00:00, 35.8kB/s]"
          }
        },
        "b06ce165db014a8d85899d711a36aa28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "063b8e295a5945b1aa61fa81212b81ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e51c208c8345426c9af3677382636cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a720266ceee413cb671125c84794a6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d4ef212d224461e8209ce14d126cff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bcea851e4ac47759ad3a97406854889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f8abd16404341ca83b21b717d4256ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "845c2cba2e28456d94d54c8d1703f820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b6e1eb73bc84d72ac2378ab67b6a532",
              "IPY_MODEL_e042b258db54416a905a08ea483e56a2",
              "IPY_MODEL_dedd17db78874e4b979d9df1e18880a2"
            ],
            "layout": "IPY_MODEL_2d6307aed0594520b6365eb7423df1a5"
          }
        },
        "1b6e1eb73bc84d72ac2378ab67b6a532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b444a45124ea4b0c9dbae93cf3f81d87",
            "placeholder": "​",
            "style": "IPY_MODEL_a77346a2c7004d828323b46a51d6cace",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "e042b258db54416a905a08ea483e56a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dbece5ace5a4c199c010c56aee6f0f5",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80e70f18076846a2bc578e418d3652eb",
            "value": 548105171
          }
        },
        "dedd17db78874e4b979d9df1e18880a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d80df97eb85645ec984fe0de19b18cd0",
            "placeholder": "​",
            "style": "IPY_MODEL_fb4d2408dd994e6da952bd9d2323af71",
            "value": " 548M/548M [00:03&lt;00:00, 125MB/s]"
          }
        },
        "2d6307aed0594520b6365eb7423df1a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b444a45124ea4b0c9dbae93cf3f81d87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a77346a2c7004d828323b46a51d6cace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dbece5ace5a4c199c010c56aee6f0f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80e70f18076846a2bc578e418d3652eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d80df97eb85645ec984fe0de19b18cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb4d2408dd994e6da952bd9d2323af71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc05fdfa1bfd471e860b4551ae348d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1df76e67d6fb4036bda6f09fa21ccb01",
              "IPY_MODEL_78ccd3abd5574ce8b8597ad735fc4863",
              "IPY_MODEL_f58b4a27a9e442bf98e19acd0e770c41"
            ],
            "layout": "IPY_MODEL_3d0b7ffa77794423a3a99cc8f786818c"
          }
        },
        "1df76e67d6fb4036bda6f09fa21ccb01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a3eeb97fec24b9b8b5c2c4f71a7edbd",
            "placeholder": "​",
            "style": "IPY_MODEL_3c56ef4d7a6540e39608e00bbda8d7a7",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "78ccd3abd5574ce8b8597ad735fc4863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b9d055deab9428fb307d32d80182e55",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0295381282764dadbb4b2475467128fb",
            "value": 124
          }
        },
        "f58b4a27a9e442bf98e19acd0e770c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6734728627b42ca9a1c51d7dca372d0",
            "placeholder": "​",
            "style": "IPY_MODEL_f7a945af172043e9b492f3b4b5430f89",
            "value": " 124/124 [00:00&lt;00:00, 3.81kB/s]"
          }
        },
        "3d0b7ffa77794423a3a99cc8f786818c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a3eeb97fec24b9b8b5c2c4f71a7edbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c56ef4d7a6540e39608e00bbda8d7a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b9d055deab9428fb307d32d80182e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0295381282764dadbb4b2475467128fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6734728627b42ca9a1c51d7dca372d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7a945af172043e9b492f3b4b5430f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dc7dc7fb3094b8f9d840d6a0c5e9669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3642d670de84023937132a0f5712c89",
              "IPY_MODEL_dd5ff3730d554ea4b3af65caadd70901",
              "IPY_MODEL_9fea82acd513401a8b2c8db5d4ec694e"
            ],
            "layout": "IPY_MODEL_1d0d42f173aa490dbd3a5bab5f257dff"
          }
        },
        "f3642d670de84023937132a0f5712c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91865eee9ccf4f71b6129d6adbee35c0",
            "placeholder": "​",
            "style": "IPY_MODEL_923fa28cefb649a8be7fff1fd50085af",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "dd5ff3730d554ea4b3af65caadd70901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef1c463526414441924170e5d7306e5e",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d06d580f717a432a9b9053a05e511907",
            "value": 1042301
          }
        },
        "9fea82acd513401a8b2c8db5d4ec694e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da32c362df834daeb890b777495e726d",
            "placeholder": "​",
            "style": "IPY_MODEL_acf4c0bcb2b544edb6344e4bc6bfc20a",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 9.96MB/s]"
          }
        },
        "1d0d42f173aa490dbd3a5bab5f257dff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91865eee9ccf4f71b6129d6adbee35c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "923fa28cefb649a8be7fff1fd50085af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef1c463526414441924170e5d7306e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d06d580f717a432a9b9053a05e511907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da32c362df834daeb890b777495e726d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acf4c0bcb2b544edb6344e4bc6bfc20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae5cb0516ef24f0aa8cc786c7a662598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49752dd8f2ad4256b591a5cf29279110",
              "IPY_MODEL_c0cc4ae6886a4d0794b5c183ab82660a",
              "IPY_MODEL_ca71a2483c5444de9c8d32ba48e5b3a5"
            ],
            "layout": "IPY_MODEL_e522567d78414e62a7b62cd7701ea6d4"
          }
        },
        "49752dd8f2ad4256b591a5cf29279110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfbc70025a6c4711aca9080fa180fcbf",
            "placeholder": "​",
            "style": "IPY_MODEL_cadff10383da46e4b969ed1f49a572f3",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "c0cc4ae6886a4d0794b5c183ab82660a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a20d17ca63d14366a3fa785c4ad51940",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af7965edc273417e86b31146ca62fe0a",
            "value": 456318
          }
        },
        "ca71a2483c5444de9c8d32ba48e5b3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb9099c296454d21b1dfac86fcd180c2",
            "placeholder": "​",
            "style": "IPY_MODEL_091a47613ccf4cc7bef0ac82a83a10da",
            "value": " 456k/456k [00:00&lt;00:00, 7.64MB/s]"
          }
        },
        "e522567d78414e62a7b62cd7701ea6d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfbc70025a6c4711aca9080fa180fcbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cadff10383da46e4b969ed1f49a572f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a20d17ca63d14366a3fa785c4ad51940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af7965edc273417e86b31146ca62fe0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb9099c296454d21b1dfac86fcd180c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "091a47613ccf4cc7bef0ac82a83a10da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d982787f18924734b1b7c131bce69ee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e64d51689e8a4d12be5f066288cf4ae3",
              "IPY_MODEL_5752a7b4a93a430da6b1fd5e9181cbb2",
              "IPY_MODEL_42c8c84bb766401aa2e3559173ac87e7"
            ],
            "layout": "IPY_MODEL_20203de075f149eb958dc37d2518b26c"
          }
        },
        "e64d51689e8a4d12be5f066288cf4ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b13ce7ecd684470a650cbf6b1c73180",
            "placeholder": "​",
            "style": "IPY_MODEL_b9a95c0aa7294f15879b14b17170fb9f",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "5752a7b4a93a430da6b1fd5e9181cbb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b8ad636023744c3b2fd74e31c10815c",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a624540f260d400f9a969044449e6e4c",
            "value": 1355256
          }
        },
        "42c8c84bb766401aa2e3559173ac87e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e858548fc39c49e19e15fded80ba0368",
            "placeholder": "​",
            "style": "IPY_MODEL_a2e12d17d617402a87a6fa26db3e3e6d",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 4.09MB/s]"
          }
        },
        "20203de075f149eb958dc37d2518b26c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b13ce7ecd684470a650cbf6b1c73180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a95c0aa7294f15879b14b17170fb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b8ad636023744c3b2fd74e31c10815c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a624540f260d400f9a969044449e6e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e858548fc39c49e19e15fded80ba0368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e12d17d617402a87a6fa26db3e3e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}